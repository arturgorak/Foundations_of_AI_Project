{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OALVXFYnQ1rD"
   },
   "source": [
    "## 1 Importy i pobranie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Numpy\n",
    "import numpy as np\n",
    "\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Reprezentacja graficzna\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "\n",
    "# Uczenie płytkie\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import  metrics\n",
    "\n",
    "\n",
    "# StandardScaler \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# inne\n",
    "from scipy.stats.distributions import uniform, randint\n",
    "import math\n",
    "\n",
    "# Uczenie głębokie\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import layers\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "*   Data - The date of observation\n",
    "*   Location - The common name of the location of the weather station\n",
    "*   Rainfall - The amount of rainfall recorded for the day in mm\n",
    "*   Evaporation - The so-called Class A pan evaporation (mm) in the 24 hours to 9am\n",
    "*   Sunshine - The number of hours of bright sunshine in the day.\n",
    "*   WindGustDir - The direction of the strongest wind gust in the 24 hours to midnight\n",
    "*   WindGustSpeed - The speed (km/h) of the strongest wind gust in the 24 hours to midnight\n",
    "*   WindDir9am - Direction of the wind at 9am\n",
    "*   WindDir3pm - Direction of the wind at 3pm\n",
    "*   WindSpeed9am- Wind speed (km/hr) averaged over 10 minutes prior to 9am\n",
    "*   WindSpeed3pm -Wind speed (km/hr) averaged over 10 minutes prior to 3pm\n",
    "*   Humidity9am - Humidity (percent) at 9am\n",
    "*   Humidity3pm - Humidity (percent) at 3pm\n",
    "*   Pressure9am - Atmospheric pressure (hpa) reduced to mean sea level at 9am\n",
    "*   Pressure3pm - Atmospheric pressure (hpa) reduced to mean sea level at 3pm\n",
    "*   Cloud9am - Fraction of sky obscured by cloud at 9am. This is measured in \"oktas\", which are a unit of eigths. It records how many\n",
    "*   Cloud3pm - Fraction of sky obscured by cloud (in \"oktas\": eighths) at 3pm. See Cload9am for a description of the values\n",
    "*   Temp9am - Temperature (degrees C) at 9am\n",
    "*   Temp3pm - Temperature (degrees C) at 3pm\n",
    "*   RainToday - Boolean: 1 if precipitation (mm) in the 24 hours to 9am exceeds 1mm, otherwise 0\n",
    "*   RainTomorrow\n",
    "The amount of next day rain in mm. Used to create response variable RainTomorrow. A kind of measure of the \"risk\".\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2 Przygotowanie danych\n",
    "Na początku sprawdźmy ile i gdzie są wartości nullowe\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ile i gdzie wartości nullowe\n",
    "data.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prawie 6% wartości WindDir9am jest nullowych i około 1.5 % WindDir3pm oraz Location. Trzeba będzie czymś je uzupełnić. W pozostałych kolumnach brakuących wartości jest < 1%"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Na początku zamieńmy wszystkie wartości yes, no na 1 i 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = data.replace([\"Yes\", \"No\"], [1, 0], regex = True)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sprawdźmy korelacje pomiędzy kolumnami aby nie było powielania informacji\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corr = data.corr()\n",
    "corr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "mask = np.triu(np.ones_like(data.corr(), dtype=np.bool))\n",
    "\n",
    "heatmap = sns.heatmap(data.corr(), mask=mask, vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
    "\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':18}, pad=16);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.pairplot( data=data, vars=('Pressure9am','Pressure3pm', 'Temp9am', 'Temp3pm', 'Evaporation', 'Sunshine'), hue='RainTomorrow' )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Zdefiniujmy funkcje która będzie dziliła nam dane na biny a nastepnie dla każdego bina wyliczała prawdopodobieństwo opadu"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def check_probability(input_name, size=10):\n",
    "  new_name = input_name + \" rounded values\"\n",
    "  data[new_name] = data[input_name].apply(lambda x: math.ceil(x))\n",
    "\n",
    "  g = sns.factorplot(x=new_name,y=\"RainTomorrow\",data=data, kind=\"bar\", size = size)\n",
    "  g.despine(left=True)\n",
    "  g = g.set_ylabels(\"rain probability\")\n",
    "\n",
    "  data.drop(labels = [new_name], axis = 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1. Date\n",
    "Spróbujmy wyciągnąć z daty miesiąc, po czym zamienić go na dane kategoryczne"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['Month'] = pd.DatetimeIndex(data['Date']).month.astype(str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.drop(labels = [\"Date\"], axis = 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sprawdźmy czy miesiąć ma wpływ na to czy następnego dnia będzie padać"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g = sns.factorplot(x=\"Month\",y=\"RainTomorrow\",data=data, kind=\"bar\", size = 6)\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels(\"rain probability\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jak widać w miesiącach jesiennych możemy się liczyć z mniejszym prawdopodobieństwem opadu"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2. Location"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['Location'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g = sns.factorplot(x=\"Location\",y=\"RainTomorrow\",data=data, kind=\"bar\", size = 10)\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels(\"rain probability\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jak widać największe szanse na opad są w CoffsHarbour oraz WitchIsland"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3. Rainfall i RainToday\n",
    "Pomiędzy Rainfall i RainToday jest zależność polegająca na tym, że jeśli w Rainfall jest wartość większa od 1 to RainToday jest True. W przeciwnym wypadku False. Także aby nie powielać informacji usuńmy kolumne RainToday"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.drop(labels = [\"RainToday\"], axis = 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jak możemy dostrzec Rainfall przyjmuje jakąś wartość kiedy w RainToday mamy 1, więć aby nie powielac informacji usuiemy kolumne RainToday i uzupełnijmy Rainfall średnią"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data, col='RainTomorrow')\n",
    "g = g.map(sns.distplot, \"Rainfall\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['Rainfall'].fillna(data['Rainfall'].mean(), inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['Rainfall'].isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4. Evaporation "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['Evaporation'].isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check_probability(\"Evaporation\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Można powiedzieć, że im większe odparowanie tym mniejsza szansa na deszcz"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.5. Sunshine"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out = pd.cut(data[\"Sunshine\"], bins=[x for x in range (0, 20)], include_lowest=True)\n",
    "ax = out.value_counts(sort=False).plot.bar(rot=0, color=\"b\", figsize=(20,6))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check_probability(\"Sunshine\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jak widać powyżej im więcej słonecznych godzin tym mniejsza szansa na deszcz jutro"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['Sunshine'].isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.6. WindDir\n",
    "Będziemy musieli uzupełnić brakujące wartości poprzez danie w miejsce nulli najczęściej występującej wartości"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['WindDir9am'].isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['WindDir9am'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#data['WindDir9am'] = data['WindDir9am'].fillna(data['WindDir9am'].mode().iloc[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['WindDir9am'].isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['WindDir9am'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#data = pd.get_dummies(data, columns = ['WindDir9am'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g = sns.factorplot(x=\"WindDir9am\",y=\"RainTomorrow\",data=data, kind=\"bar\", size = 10)\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels(\"rain probability\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Największe szanse na deszcz są przy wietrze wiejącym wkierunku SSW (południowo zachodnim, ale bardziej skierowanemu na południe). Za chwilę zobaczymy czy podobne obserwacje będą przy wietsze o godzinie 15.00"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['WindDir3pm'].isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['WindDir3pm'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#data['WindDir3pm'] = data['WindDir3pm'].fillna(data['WindDir3pm'].mode().iloc[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['WindDir3pm'].isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#data = pd.get_dummies(data, columns = ['WindDir3pm'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g = sns.factorplot(x=\"WindDir3pm\",y=\"RainTomorrow\",data=data, kind=\"bar\", size = 10)\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels(\"rain probability\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.7. Unnamed: 0\n",
    "Wyrzućmy tą nic nie wnoszącą kolumne"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.drop(labels = [\"Unnamed: 0\"], axis = 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.8. WindSpeed\n",
    "Zastąpmy brakujące wartości wartościami średnimi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['WindSpeed9am'].fillna(data['WindSpeed9am'].mean(), inplace=True)\n",
    "data['WindSpeed3pm'].fillna(data['WindSpeed3pm'].mean(), inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check_probability(\"WindSpeed9am\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check_probability(\"WindSpeed3pm\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Humidity9am       14\n",
    "Humidity3pm       13\n",
    "Pressure9am       23\n",
    "Pressure3pm       16\n",
    "Cloud9am           0\n",
    "Cloud3pm           0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.9. Humidity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['Humidity3pm'].fillna(data['Humidity3pm'].mean(), inplace=True)\n",
    "data['Humidity9am'].fillna(data['Humidity9am'].mean(), inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check_probability(\"Humidity9am\", 14)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check_probability(\"Humidity3pm\", 15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Również można dostrzec zależność, że im większa wilgotność tym większa szansa na opad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.10. Pressure"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['Pressure3pm'].fillna(data['Pressure3pm'].mean(), inplace=True) \n",
    "data['Pressure9am'].fillna(data['Pressure9am'].mean(), inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check_probability('Pressure9am', 15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check_probability('Pressure3pm', 20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.11. Cloud"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check_probability(\"Cloud9am\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check_probability(\"Cloud3pm\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "W obu przypadkach możemy dojśc do wniosku, że im większa część nieba jest przysłonięta chmurami to tym większe prawdopodobieństwo opadów"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3 Pipeline'y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pipeline dla numerycznych\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "numerical_fields = [\"Evaporation\", \"Rainfall\", \"Sunshine\", \"WindGustSpeed\", 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm']\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        (\"select_numeric\", DataFrameSelector(numerical_fields)),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pipeline dla kategorycznych"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "catbin = [\"Location\",\"WindGustDir\" ,\"WindDir9am\", \"WindDir3pm\", \"Month\"]\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        (\"select_cat\", DataFrameSelector(catbin)),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse=False, handle_unknown = 'ignore')),\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4 Podział danych na train i test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = data[\"RainTomorrow\"]\n",
    "X = data.drop(\"RainTomorrow\", axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_pipeline.fit_transform(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cat_pipeline.fit_transform(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seed=123\n",
    "kfold = StratifiedKFold(n_splits=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5 Uczenie modeli"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.1 Uczenie płytkie"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1.1 Decision Tree"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('classifier', DecisionTreeClassifier())\n",
    "    ])\n",
    "\n",
    "dt_param_grid = {\n",
    "    'classifier__max_depth': range(2, 10),\n",
    "    'classifier__max_features': range(2, 14),\n",
    "    }\n",
    "\n",
    "gsDT = GridSearchCV(pipe, dt_param_grid, cv=kfold, verbose=10)\n",
    "gsDT.fit(X_train,y_train)\n",
    "DT_best = gsDT.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1.2 Random Forest Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', RandomForestClassifier())])\n",
    "\n",
    "\n",
    "\n",
    "rf_param_grid = { \n",
    "    'classifier__n_estimators': [100, 300],\n",
    "    'classifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'classifier__max_depth': [3,5,7,9],\n",
    "    'classifier__criterion': ['gini']\n",
    "}\n",
    "\n",
    "gsRFC = GridSearchCV(pipe, rf_param_grid, cv=kfold, verbose=10)\n",
    "gsRFC.fit(X_train,y_train)\n",
    "RFC_best = gsRFC.best_estimator_\n",
    "\n",
    "print(gsRFC.best_score_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1.3 Gradient Boosting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Gradient boosting tunning\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', GradientBoostingClassifier())])\n",
    "\n",
    "\n",
    "gb_param_grid = {'classifier__loss' : [\"deviance\"],\n",
    "              'classifier__n_estimators' : [100,200],\n",
    "              'classifier__learning_rate': [0.05, 0.1],\n",
    "              'classifier__max_depth': [4, 8, 12],\n",
    "              'classifier__max_features': [0.5, 0.3, 0.1] \n",
    "              }\n",
    "\n",
    "gsGBC = GridSearchCV(pipe, gb_param_grid, cv=kfold, verbose=10)\n",
    "\n",
    "gsGBC.fit(X_train,y_train)\n",
    "\n",
    "GBC_best = gsGBC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsGBC.best_score_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1.4 Logistic Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', LogisticRegression())])\n",
    "\n",
    "LR_param_grid = {\n",
    "    'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "     'classifier__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "\n",
    "gsLR = GridSearchCV(pipe ,param_grid = LR_param_grid, cv=kfold, verbose = 10)\n",
    "\n",
    "gsLR.fit(X_train,y_train)\n",
    "\n",
    "LR_best = gsLR.best_estimator_\n",
    "\n",
    "gsLR.best_score_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1.5 XGBoost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', XGBClassifier())])\n",
    "\n",
    "param_distribution = {\n",
    "    'classifier__max_depth': randint(3, 20),\n",
    "    'classifier__learning_rate': uniform(0.001, 0.1-0.001),\n",
    "    'classifier__n_estimators': randint(50, 600),\n",
    "    'classifier__gamma': uniform(0,2),\n",
    "    'classifier__colsample_bytree': uniform(0.5, 0.5),\n",
    "    'classifier__subsample': uniform(0.5, 0.5),\n",
    "    'classifier__min_child_weight': randint(1, 11)\n",
    "}\n",
    "\n",
    "\n",
    "gsXGB = RandomizedSearchCV(pipe, param_distribution, n_iter=32, verbose=10 )\n",
    "\n",
    "gsXGB.fit(X_train, y_train)\n",
    "XGB_best = gsXGB.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsXGB.best_score_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1.6 SVC linear"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', SVC(kernel=\"linear\"))])\n",
    "\n",
    "param_grid = {\n",
    "          \n",
    "            'classifier__gamma': [0.001, 0.1, 1, ],\n",
    "            'classifier__C': [0.001, 0.1, 1,],\n",
    "            'classifier__probability': [True]\n",
    "}\n",
    "\n",
    "gsSVC_linear = GridSearchCV(pipe, param_grid, cv=kfold, verbose=10)\n",
    "\n",
    "gsSVC_linear.fit(X_train, y_train)\n",
    "\n",
    "gsSVC_linear_best = gsSVC_linear.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsSVC_linear.best_score_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1.7 Ada Boost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DTC = DecisionTreeClassifier()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', AdaBoostClassifier(DTC, random_state=7))])\n",
    "\n",
    "ada_param_grid = {\"classifier__base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "              \"classifier__base_estimator__splitter\" :   [\"best\", \"random\"],\n",
    "              \"classifier__algorithm\" : [\"SAMME\",\"SAMME.R\"],\n",
    "              \"classifier__n_estimators\" :[1,2],\n",
    "              \"classifier__learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5]}\n",
    "\n",
    "gsAda = GridSearchCV(pipe ,param_grid = ada_param_grid, cv=kfold, verbose = 10)\n",
    "\n",
    "gsAda.fit(X_train, y_train)\n",
    "\n",
    "ada_best = gsAda.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1.9 Voting classifier (hard)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Hard voting \n",
    "\n",
    "hard_voting_class = VotingClassifier(estimators=[ ('DT', DT_best),('RFC', RFC_best),\n",
    "('GBC',GBC_best), ('XGB', XGB_best)], voting='hard')\n",
    "\n",
    "hard_voting = hard_voting_class.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1.10 Voitng classifier (soft)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Soft voting\n",
    "\n",
    "\n",
    "soft_voting_class = VotingClassifier(estimators=[ ('DT', DT_best),('XGBoost', RFC_best),\n",
    "('GBC',GBC_best), ('XGB', XGB_best)], voting='soft')\n",
    "\n",
    "soft_voting = soft_voting_class.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1.11 Porównianie modeli płytkich"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('DecisionTree', gsDT.best_estimator_))\n",
    "models.append(('RandomForest', gsRFC.best_estimator_))\n",
    "models.append(('GradientBoosting', gsGBC.best_estimator_))\n",
    "models.append(('XGBoost', gsXGB.best_estimator_))\n",
    "models.append(('LogisticRegression', gsLR.best_estimator_))\n",
    "models.append(('SVC_linear', gsSVC_linear.best_estimator_))\n",
    "models.append(('Ada Boost', gsAda.best_estimator_))\n",
    "models.append(('Hard voting', hard_voting))\n",
    "models.append(('Soft voting', soft_voting))\n",
    "\n",
    "\n",
    "precision_score = []\n",
    "recall_score = []\n",
    "f1_score = []\n",
    "accuracy_score = []\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    print(\"precision_score: {}\".format(metrics.precision_score(y_test, model.predict(X_test)) ))\n",
    "    print(\"recall_score: {}\".format( metrics.recall_score(y_test, model.predict(X_test)) ))\n",
    "    print(\"f1_score: {}\".format( metrics.f1_score(y_test, model.predict(X_test)) ))\n",
    "    print(\"accuracy_score: {}\".format( metrics.accuracy_score(y_test, model.predict(X_test)) ))\n",
    "    precision_score.append(metrics.precision_score(y_test, model.predict(X_test)))\n",
    "    recall_score.append(metrics.recall_score(y_test, model.predict(X_test)))\n",
    "    f1_score.append( metrics.f1_score(y_test, model.predict(X_test)))\n",
    "    accuracy_score.append(metrics.accuracy_score(y_test, model.predict(X_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models2 = []\n",
    "models2.append(('DecisionTree', gsDT.best_estimator_))\n",
    "models2.append(('RandomForest', gsRFC.best_estimator_))\n",
    "models2.append(('GradientBoosting', gsGBC.best_estimator_))\n",
    "models2.append(('XGBoost', gsXGB.best_estimator_))\n",
    "models2.append(('LogisticRegression', gsLR.best_estimator_))\n",
    "models.append(('SVC_linear', gsSVC_linear.best_estimator_))\n",
    "models2.append(('Ada Boost', gsAda.best_estimator_))\n",
    "#models2.append(('Hard voting', hard_voting))\n",
    "models2.append(('Soft voting', soft_voting))\n",
    "\n",
    "\n",
    "for name, model in models2:\n",
    "    print(name)\n",
    "    print(\"roc_score: {}\".format(roc_auc_score(y_test, model.predict(X_test))))\n",
    "   \n",
    "    # calculate the fpr and tpr for all thresholds of the classification\n",
    "    probs = model.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    " \n",
    "    # method I: plt\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, label = '%s AUC = %0.10f' % (name, roc_auc))\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([-0.1, 1.1], [0, 1],'r--')\n",
    "    plt.xlim([-0.1, 1.1])\n",
    "    plt.ylim([-0.1, 1.1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (25,12)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d = {'precision_score': precision_score, \n",
    "     'recall_score': recall_score, \n",
    "     'f1_score': f1_score,\n",
    "     'accuracy_score' : accuracy_score\n",
    "    }\n",
    "df = pd.DataFrame(data=d)\n",
    "df.insert(loc=0, column='Method', value=['Decision tree', 'Random Forest', 'Gradient Boosting', 'XGBoost', 'Logistic Regression','SVC Linear', 'Ada Boost','Hard Voting', 'Soft Voting'])\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.2 Uczenie głębokie"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Najpierw przetwórzmy nasze dane przy pomocy pipelineów"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train2 = preprocess_pipeline.transform(X_train)\n",
    "X_test2 = preprocess_pipeline.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2.1 Sieć bez bajerów"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model1 = keras.models.Sequential()\n",
    "model1.add(layers.Dense(82, input_dim=82, activation='sigmoid'))\n",
    "model1.add(layers.Dense(41, input_dim=82, activation='sigmoid'))\n",
    "model1.add(layers.Dense(20, input_dim=82, activation='sigmoid'))\n",
    "model1.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history1 = model1.fit(X_train2, y_train, epochs=100, validation_data=(X_test2, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(history1.history).plot(figsize=(25, 12))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2.2 Sieć z early stoppingiem"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model2 = keras.models.Sequential()\n",
    "model2.add(layers.Dense(82, input_dim=82, activation='elu'))\n",
    "model2.add(layers.Dense(41, input_dim=82, activation='elu'))\n",
    "model2.add(layers.Dense(20, input_dim=82, activation='elu'))\n",
    "model2.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
    "history2 = model2.fit(X_train2, y_train, epochs=100, validation_data=(X_test2, y_test), callbacks=[early_stopping])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(history2.history).plot(figsize=(25, 12))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2.3 Sieć z BatchNormalization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Flatten(input_shape=[82,]))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Activation('sigmoid'))\n",
    "\n",
    "model3.add(Dense(300))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Activation('sigmoid'))\n",
    "\n",
    "model3.add(Dense(100))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Activation('sigmoid'))\n",
    "\n",
    "model3.add(Dense(1))\n",
    "model3.add(Activation('sigmoid'))\n",
    "\n",
    "model3.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history3 = model3.fit(X_train2, y_train, epochs=100, validation_data=(X_test2, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(history3.history).plot(figsize=(25, 12))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2.4 Sieć z BatchNormalization i Dropoutem"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Flatten(input_shape=[82,]))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Activation('elu'))\n",
    "model4.add(Dropout(0.3))\n",
    "\n",
    "model4.add(Dense(300))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Activation('elu'))\n",
    "model4.add(Dropout(0.3))\n",
    "\n",
    "model4.add(Dense(100))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Activation('elu'))\n",
    "model4.add(Dropout(0.3))\n",
    "\n",
    "model4.add(Dense(1))\n",
    "model4.add(Activation('sigmoid'))\n",
    "\n",
    "model4.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history4 = model4.fit(X_train2, y_train, epochs=100, validation_data=(X_test2, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(history4.history).plot(figsize=(25, 12))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2.5 Randomized Search"
   ],
   "metadata": {
    "id": "6diPqHsfH4fT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[82,], activation_function='sigmoid'):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=activation_function))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    \n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "metadata": {
    "id": "yuqnnGvwNR2Z"
   },
   "execution_count": 85,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "keras_class = tf.keras.wrappers.scikit_learn.KerasClassifier(build_model)\n",
    "keras_class"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DSy7QpqnNXwW",
    "outputId": "b3085d0b-fe3b-46fc-a8c5-c37a2eb9de07"
   },
   "execution_count": 86,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.wrappers.scikit_learn.KerasClassifier at 0x7f980d9df210>"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "param_distribs = {\n",
    "    \"n_hidden\": [2, 3, 4, 5],\n",
    "    \"n_neurons\": np.arange(1, 100), \n",
    "    \"activation_function\": ['relu', 'elu', 'sigmoid']\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_class, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train2, y_train, epochs=100, validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=20, mode='min', verbose=1)])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EhXhtA3eNarZ",
    "outputId": "e4b86250-2825-4816-c0b8-afe7138ac21f"
   },
   "execution_count": 87,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 21: early stopping\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 3.5709 - accuracy: 0.7685\n",
      "[CV] END activation_function=sigmoid, n_hidden=5, n_neurons=38; total time=  21.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 4ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 21: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 11.7610 - accuracy: 0.2288\n",
      "[CV] END activation_function=sigmoid, n_hidden=5, n_neurons=38; total time=  12.0s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 21: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.6673 - accuracy: 0.7623\n",
      "[CV] END activation_function=sigmoid, n_hidden=5, n_neurons=38; total time=  11.2s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 21: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 11.7190 - accuracy: 0.2315\n",
      "[CV] END activation_function=sigmoid, n_hidden=2, n_neurons=69; total time=  10.3s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 21: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.5285 - accuracy: 0.7713\n",
      "[CV] END activation_function=sigmoid, n_hidden=2, n_neurons=69; total time=  11.0s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5178 - accuracy: 0.7661 - val_loss: 0.4732 - val_accuracy: 0.7825\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7696 - val_loss: 0.4364 - val_accuracy: 0.7825\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4571 - accuracy: 0.7750 - val_loss: 0.4166 - val_accuracy: 0.7962\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 10.7040 - accuracy: 0.2814 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 23: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 11.6237 - accuracy: 0.2377\n",
      "[CV] END activation_function=sigmoid, n_hidden=2, n_neurons=69; total time=  21.2s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 21: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.5709 - accuracy: 0.7685\n",
      "[CV] END activation_function=sigmoid, n_hidden=5, n_neurons=42; total time=  22.0s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 21: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.5285 - accuracy: 0.7713\n",
      "[CV] END activation_function=sigmoid, n_hidden=5, n_neurons=42; total time=  21.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 21: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 11.6237 - accuracy: 0.2377\n",
      "[CV] END activation_function=sigmoid, n_hidden=5, n_neurons=42; total time=  11.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5438 - accuracy: 0.7667 - val_loss: 0.5430 - val_accuracy: 0.7675\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7667 - val_loss: 0.5424 - val_accuracy: 0.7675\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7667 - val_loss: 0.5424 - val_accuracy: 0.7675\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5438 - accuracy: 0.7667 - val_loss: 0.5438 - val_accuracy: 0.7675\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5440 - accuracy: 0.7667 - val_loss: 0.5424 - val_accuracy: 0.7675\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7667 - val_loss: 0.5429 - val_accuracy: 0.7675\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7667 - val_loss: 0.5426 - val_accuracy: 0.7675\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7667 - val_loss: 0.5424 - val_accuracy: 0.7675\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7667 - val_loss: 0.5424 - val_accuracy: 0.7675\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7667 - val_loss: 0.5424 - val_accuracy: 0.7675\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7667 - val_loss: 0.5437 - val_accuracy: 0.7675\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7667 - val_loss: 0.5426 - val_accuracy: 0.7675\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.7667 - val_loss: 0.5424 - val_accuracy: 0.7675\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7667 - val_loss: 0.5424 - val_accuracy: 0.7675\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5428 - val_accuracy: 0.7675\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7667 - val_loss: 0.5424 - val_accuracy: 0.7675\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7667 - val_loss: 0.5423 - val_accuracy: 0.7675\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7667 - val_loss: 0.5434 - val_accuracy: 0.7675\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.7667 - val_loss: 0.5423 - val_accuracy: 0.7675\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7667 - val_loss: 0.5426 - val_accuracy: 0.7675\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5436 - val_accuracy: 0.7675\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5442 - accuracy: 0.7667 - val_loss: 0.5424 - val_accuracy: 0.7675\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.7667 - val_loss: 0.5424 - val_accuracy: 0.7675\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7667 - val_loss: 0.5425 - val_accuracy: 0.7675\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7667 - val_loss: 0.5425 - val_accuracy: 0.7675\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5427 - val_accuracy: 0.7675\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7667 - val_loss: 0.5423 - val_accuracy: 0.7675\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7667 - val_loss: 0.5427 - val_accuracy: 0.7675\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5439 - accuracy: 0.7667 - val_loss: 0.5428 - val_accuracy: 0.7675\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7667 - val_loss: 0.5424 - val_accuracy: 0.7675\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7667 - val_loss: 0.5423 - val_accuracy: 0.7675\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5427 - val_accuracy: 0.7675\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.7667 - val_loss: 0.5423 - val_accuracy: 0.7675\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7667 - val_loss: 0.5437 - val_accuracy: 0.7675\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7667 - val_loss: 0.5425 - val_accuracy: 0.7675\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5423 - val_accuracy: 0.7675\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7667 - val_loss: 0.5424 - val_accuracy: 0.7675\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7667 - val_loss: 0.5426 - val_accuracy: 0.7675\n",
      "Epoch 39/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7667 - val_loss: 0.5425 - val_accuracy: 0.7675\n",
      "Epoch 40/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7667 - val_loss: 0.5423 - val_accuracy: 0.7675\n",
      "Epoch 41/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5423 - val_accuracy: 0.7675\n",
      "Epoch 42/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7667 - val_loss: 0.5424 - val_accuracy: 0.7675\n",
      "Epoch 43/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7667 - val_loss: 0.5423 - val_accuracy: 0.7675\n",
      "Epoch 44/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5428 - val_accuracy: 0.7675\n",
      "Epoch 45/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7667 - val_loss: 0.5422 - val_accuracy: 0.7675\n",
      "Epoch 46/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5423 - val_accuracy: 0.7675\n",
      "Epoch 47/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7667 - val_loss: 0.5424 - val_accuracy: 0.7675\n",
      "Epoch 48/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7667 - val_loss: 0.5425 - val_accuracy: 0.7675\n",
      "Epoch 49/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7667 - val_loss: 0.5422 - val_accuracy: 0.7675\n",
      "Epoch 50/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7667 - val_loss: 0.5422 - val_accuracy: 0.7675\n",
      "Epoch 51/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7667 - val_loss: 0.5422 - val_accuracy: 0.7675\n",
      "Epoch 52/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5423 - val_accuracy: 0.7675\n",
      "Epoch 53/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7667 - val_loss: 0.5427 - val_accuracy: 0.7675\n",
      "Epoch 54/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7667 - val_loss: 0.5428 - val_accuracy: 0.7675\n",
      "Epoch 55/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5423 - val_accuracy: 0.7675\n",
      "Epoch 56/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5423 - val_accuracy: 0.7675\n",
      "Epoch 57/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7667 - val_loss: 0.5428 - val_accuracy: 0.7675\n",
      "Epoch 58/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7667 - val_loss: 0.5427 - val_accuracy: 0.7675\n",
      "Epoch 59/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5432 - val_accuracy: 0.7675\n",
      "Epoch 60/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5423 - val_accuracy: 0.7675\n",
      "Epoch 61/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5438 - accuracy: 0.7667 - val_loss: 0.5422 - val_accuracy: 0.7675\n",
      "Epoch 62/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5423 - val_accuracy: 0.7675\n",
      "Epoch 63/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7667 - val_loss: 0.5425 - val_accuracy: 0.7675\n",
      "Epoch 64/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5422 - val_accuracy: 0.7675\n",
      "Epoch 65/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7667 - val_loss: 0.5424 - val_accuracy: 0.7675\n",
      "Epoch 66/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7667 - val_loss: 0.5422 - val_accuracy: 0.7675\n",
      "Epoch 67/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7667 - val_loss: 0.5425 - val_accuracy: 0.7675\n",
      "Epoch 68/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7667 - val_loss: 0.5444 - val_accuracy: 0.7675\n",
      "Epoch 69/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5429 - val_accuracy: 0.7675\n",
      "Epoch 70/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5425 - val_accuracy: 0.7675\n",
      "Epoch 71/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7667 - val_loss: 0.5423 - val_accuracy: 0.7675\n",
      "Epoch 72/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5423 - val_accuracy: 0.7675\n",
      "Epoch 73/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5423 - val_accuracy: 0.7675\n",
      "Epoch 74/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5422 - val_accuracy: 0.7675\n",
      "Epoch 75/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5422 - val_accuracy: 0.7675\n",
      "Epoch 76/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5423 - val_accuracy: 0.7675\n",
      "Epoch 77/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5422 - val_accuracy: 0.7675\n",
      "Epoch 78/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5422 - val_accuracy: 0.7675\n",
      "Epoch 79/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5421 - val_accuracy: 0.7675\n",
      "Epoch 80/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7667 - val_loss: 0.5435 - val_accuracy: 0.7675\n",
      "Epoch 81/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5425 - val_accuracy: 0.7675\n",
      "Epoch 82/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5436 - accuracy: 0.7667 - val_loss: 0.5426 - val_accuracy: 0.7675\n",
      "Epoch 83/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7667 - val_loss: 0.5423 - val_accuracy: 0.7675\n",
      "Epoch 84/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7667 - val_loss: 0.5424 - val_accuracy: 0.7675\n",
      "Epoch 85/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5421 - val_accuracy: 0.7675\n",
      "Epoch 86/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7667 - val_loss: 0.5424 - val_accuracy: 0.7675\n",
      "Epoch 87/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7667 - val_loss: 0.5425 - val_accuracy: 0.7675\n",
      "Epoch 88/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7667 - val_loss: 0.5435 - val_accuracy: 0.7675\n",
      "Epoch 89/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5422 - val_accuracy: 0.7675\n",
      "Epoch 90/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7667 - val_loss: 0.5435 - val_accuracy: 0.7675\n",
      "Epoch 91/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.5427 - val_accuracy: 0.7675\n",
      "Epoch 92/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7667 - val_loss: 0.5423 - val_accuracy: 0.7675\n",
      "Epoch 93/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7667 - val_loss: 0.5444 - val_accuracy: 0.7675\n",
      "Epoch 94/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7667 - val_loss: 0.5427 - val_accuracy: 0.7675\n",
      "Epoch 95/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7667 - val_loss: 0.5421 - val_accuracy: 0.7675\n",
      "Epoch 96/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7667 - val_loss: 0.5427 - val_accuracy: 0.7675\n",
      "Epoch 97/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7667 - val_loss: 0.5421 - val_accuracy: 0.7675\n",
      "Epoch 98/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7667 - val_loss: 0.5421 - val_accuracy: 0.7675\n",
      "Epoch 99/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7667 - val_loss: 0.5423 - val_accuracy: 0.7675\n",
      "Epoch 100/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7667 - val_loss: 0.5450 - val_accuracy: 0.7675\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7685\n",
      "[CV] END activation_function=sigmoid, n_hidden=5, n_neurons=7; total time=  47.9s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6227 - accuracy: 0.7651 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 21: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.5285 - accuracy: 0.7713\n",
      "[CV] END activation_function=sigmoid, n_hidden=5, n_neurons=7; total time=  11.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 21: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.6673 - accuracy: 0.7623\n",
      "[CV] END activation_function=sigmoid, n_hidden=5, n_neurons=7; total time=  21.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 21: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.5709 - accuracy: 0.7685\n",
      "[CV] END activation_function=sigmoid, n_hidden=4, n_neurons=55; total time=  11.2s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5462 - accuracy: 0.7651 - val_loss: 0.5410 - val_accuracy: 0.7675\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7651 - val_loss: 0.5425 - val_accuracy: 0.7675\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7651 - val_loss: 0.5401 - val_accuracy: 0.7675\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7651 - val_loss: 0.5428 - val_accuracy: 0.7675\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7651 - val_loss: 0.5475 - val_accuracy: 0.7675\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5453 - accuracy: 0.7651 - val_loss: 0.5416 - val_accuracy: 0.7675\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7651 - val_loss: 0.5389 - val_accuracy: 0.7675\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7651 - val_loss: 0.5413 - val_accuracy: 0.7675\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7651 - val_loss: 0.5381 - val_accuracy: 0.7675\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7651 - val_loss: 0.5450 - val_accuracy: 0.7675\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7651 - val_loss: 0.5408 - val_accuracy: 0.7675\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5431 - accuracy: 0.7651 - val_loss: 0.5376 - val_accuracy: 0.7675\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7651 - val_loss: 0.5439 - val_accuracy: 0.7675\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7651 - val_loss: 0.5363 - val_accuracy: 0.7675\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5408 - accuracy: 0.7651 - val_loss: 0.5362 - val_accuracy: 0.7675\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7651 - val_loss: 0.5391 - val_accuracy: 0.7675\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5407 - accuracy: 0.7651 - val_loss: 0.5403 - val_accuracy: 0.7675\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.7651 - val_loss: 0.5417 - val_accuracy: 0.7675\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7651 - val_loss: 0.5336 - val_accuracy: 0.7675\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7651 - val_loss: 0.5334 - val_accuracy: 0.7675\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7651 - val_loss: 0.5380 - val_accuracy: 0.7675\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7651 - val_loss: 0.5381 - val_accuracy: 0.7675\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7651 - val_loss: 0.5312 - val_accuracy: 0.7675\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7651 - val_loss: 0.5309 - val_accuracy: 0.7675\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7651 - val_loss: 0.5307 - val_accuracy: 0.7675\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7651 - val_loss: 0.5447 - val_accuracy: 0.7675\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7651 - val_loss: 0.5281 - val_accuracy: 0.7675\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7651 - val_loss: 0.5271 - val_accuracy: 0.7675\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7651 - val_loss: 0.5323 - val_accuracy: 0.7675\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7651 - val_loss: 0.5280 - val_accuracy: 0.7675\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5298 - accuracy: 0.7651 - val_loss: 0.5252 - val_accuracy: 0.7675\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7651 - val_loss: 0.5239 - val_accuracy: 0.7675\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5281 - accuracy: 0.7651 - val_loss: 0.5224 - val_accuracy: 0.7675\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7651 - val_loss: 0.5216 - val_accuracy: 0.7675\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7651 - val_loss: 0.5193 - val_accuracy: 0.7675\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5209 - accuracy: 0.7651 - val_loss: 0.5173 - val_accuracy: 0.7675\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5202 - accuracy: 0.7651 - val_loss: 0.5154 - val_accuracy: 0.7675\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7651 - val_loss: 0.5153 - val_accuracy: 0.7675\n",
      "Epoch 39/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5164 - accuracy: 0.7651 - val_loss: 0.5126 - val_accuracy: 0.7675\n",
      "Epoch 40/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5134 - accuracy: 0.7651 - val_loss: 0.5100 - val_accuracy: 0.7675\n",
      "Epoch 41/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5104 - accuracy: 0.7651 - val_loss: 0.5096 - val_accuracy: 0.7675\n",
      "Epoch 42/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5094 - accuracy: 0.7651 - val_loss: 0.5052 - val_accuracy: 0.7675\n",
      "Epoch 43/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7651 - val_loss: 0.5045 - val_accuracy: 0.7675\n",
      "Epoch 44/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5018 - accuracy: 0.7651 - val_loss: 0.5023 - val_accuracy: 0.7675\n",
      "Epoch 45/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7651 - val_loss: 0.4947 - val_accuracy: 0.7675\n",
      "Epoch 46/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4959 - accuracy: 0.7651 - val_loss: 0.4922 - val_accuracy: 0.7675\n",
      "Epoch 47/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7651 - val_loss: 0.4908 - val_accuracy: 0.7675\n",
      "Epoch 48/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7651 - val_loss: 0.4832 - val_accuracy: 0.7675\n",
      "Epoch 49/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4825 - accuracy: 0.7651 - val_loss: 0.4787 - val_accuracy: 0.7675\n",
      "Epoch 50/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7651 - val_loss: 0.4786 - val_accuracy: 0.7675\n",
      "Epoch 51/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7651 - val_loss: 0.4684 - val_accuracy: 0.7675\n",
      "Epoch 52/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7651 - val_loss: 0.4626 - val_accuracy: 0.7675\n",
      "Epoch 53/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7646 - val_loss: 0.4570 - val_accuracy: 0.7675\n",
      "Epoch 54/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4558 - accuracy: 0.7654 - val_loss: 0.4516 - val_accuracy: 0.7675\n",
      "Epoch 55/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4500 - accuracy: 0.7671 - val_loss: 0.4461 - val_accuracy: 0.7675\n",
      "Epoch 56/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4544 - accuracy: 0.7643 - val_loss: 0.4435 - val_accuracy: 0.7675\n",
      "Epoch 57/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7678 - val_loss: 0.4502 - val_accuracy: 0.7675\n",
      "Epoch 58/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7725 - val_loss: 0.4322 - val_accuracy: 0.7675\n",
      "Epoch 59/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7682 - val_loss: 0.4278 - val_accuracy: 0.7675\n",
      "Epoch 60/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7814 - val_loss: 0.4220 - val_accuracy: 0.7713\n",
      "Epoch 61/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4415 - accuracy: 0.7864 - val_loss: 0.4296 - val_accuracy: 0.7688\n",
      "Epoch 62/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 4.4147 - accuracy: 0.5931 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 63/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 64/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 65/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 66/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 67/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 68/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 69/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 70/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 71/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 72/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 73/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 74/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 75/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 76/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 77/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 78/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 79/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 80/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.6678 - accuracy: 0.2349 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 80: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 11.7610 - accuracy: 0.2288\n",
      "[CV] END activation_function=sigmoid, n_hidden=4, n_neurons=55; total time=  41.7s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5468 - accuracy: 0.7632 - val_loss: 0.5231 - val_accuracy: 0.7825\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5425 - accuracy: 0.7685 - val_loss: 0.5247 - val_accuracy: 0.7825\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7685 - val_loss: 0.5295 - val_accuracy: 0.7825\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5429 - accuracy: 0.7685 - val_loss: 0.5321 - val_accuracy: 0.7825\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7685 - val_loss: 0.5269 - val_accuracy: 0.7825\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7685 - val_loss: 0.5216 - val_accuracy: 0.7825\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7685 - val_loss: 0.5240 - val_accuracy: 0.7825\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7685 - val_loss: 0.5269 - val_accuracy: 0.7825\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7685 - val_loss: 0.5220 - val_accuracy: 0.7825\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7685 - val_loss: 0.5208 - val_accuracy: 0.7825\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7685 - val_loss: 0.5261 - val_accuracy: 0.7825\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7685 - val_loss: 0.5202 - val_accuracy: 0.7825\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.7685 - val_loss: 0.5207 - val_accuracy: 0.7825\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.7685 - val_loss: 0.5218 - val_accuracy: 0.7825\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7685 - val_loss: 0.5266 - val_accuracy: 0.7825\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7685 - val_loss: 0.5291 - val_accuracy: 0.7825\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.7685 - val_loss: 0.5292 - val_accuracy: 0.7825\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7685 - val_loss: 0.5201 - val_accuracy: 0.7825\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7685 - val_loss: 0.5187 - val_accuracy: 0.7825\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.7685 - val_loss: 0.5190 - val_accuracy: 0.7825\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7685 - val_loss: 0.5199 - val_accuracy: 0.7825\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7685 - val_loss: 0.5348 - val_accuracy: 0.7825\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7685 - val_loss: 0.5178 - val_accuracy: 0.7825\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7685 - val_loss: 0.5172 - val_accuracy: 0.7825\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7685 - val_loss: 0.5349 - val_accuracy: 0.7825\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7685 - val_loss: 0.5157 - val_accuracy: 0.7825\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7685 - val_loss: 0.5156 - val_accuracy: 0.7825\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7685 - val_loss: 0.5173 - val_accuracy: 0.7825\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7685 - val_loss: 0.5144 - val_accuracy: 0.7825\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7685 - val_loss: 0.5149 - val_accuracy: 0.7825\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7685 - val_loss: 0.5133 - val_accuracy: 0.7825\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7685 - val_loss: 0.5127 - val_accuracy: 0.7825\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7685 - val_loss: 0.5120 - val_accuracy: 0.7825\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7685 - val_loss: 0.5133 - val_accuracy: 0.7825\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7685 - val_loss: 0.5126 - val_accuracy: 0.7825\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7685 - val_loss: 0.5152 - val_accuracy: 0.7825\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5289 - accuracy: 0.7685 - val_loss: 0.5105 - val_accuracy: 0.7825\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7685 - val_loss: 0.5083 - val_accuracy: 0.7825\n",
      "Epoch 39/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5274 - accuracy: 0.7685 - val_loss: 0.5116 - val_accuracy: 0.7825\n",
      "Epoch 40/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7685 - val_loss: 0.5121 - val_accuracy: 0.7825\n",
      "Epoch 41/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7685 - val_loss: 0.5062 - val_accuracy: 0.7825\n",
      "Epoch 42/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7685 - val_loss: 0.5093 - val_accuracy: 0.7825\n",
      "Epoch 43/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7685 - val_loss: 0.5157 - val_accuracy: 0.7825\n",
      "Epoch 44/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5213 - accuracy: 0.7685 - val_loss: 0.5013 - val_accuracy: 0.7825\n",
      "Epoch 45/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5198 - accuracy: 0.7685 - val_loss: 0.5010 - val_accuracy: 0.7825\n",
      "Epoch 46/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7685 - val_loss: 0.4986 - val_accuracy: 0.7825\n",
      "Epoch 47/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7685 - val_loss: 0.4966 - val_accuracy: 0.7825\n",
      "Epoch 48/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7685 - val_loss: 0.5031 - val_accuracy: 0.7825\n",
      "Epoch 49/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7685 - val_loss: 0.4924 - val_accuracy: 0.7825\n",
      "Epoch 50/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7685 - val_loss: 0.4909 - val_accuracy: 0.7825\n",
      "Epoch 51/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5099 - accuracy: 0.7685 - val_loss: 0.5040 - val_accuracy: 0.7825\n",
      "Epoch 52/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5068 - accuracy: 0.7685 - val_loss: 0.4863 - val_accuracy: 0.7825\n",
      "Epoch 53/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7685 - val_loss: 0.4821 - val_accuracy: 0.7825\n",
      "Epoch 54/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7685 - val_loss: 0.4789 - val_accuracy: 0.7825\n",
      "Epoch 55/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7685 - val_loss: 0.4778 - val_accuracy: 0.7825\n",
      "Epoch 56/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7685 - val_loss: 0.4742 - val_accuracy: 0.7825\n",
      "Epoch 57/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7685 - val_loss: 0.4714 - val_accuracy: 0.7825\n",
      "Epoch 58/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7685 - val_loss: 0.4641 - val_accuracy: 0.7825\n",
      "Epoch 59/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7685 - val_loss: 0.4591 - val_accuracy: 0.7825\n",
      "Epoch 60/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4757 - accuracy: 0.7685 - val_loss: 0.4526 - val_accuracy: 0.7825\n",
      "Epoch 61/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4693 - accuracy: 0.7685 - val_loss: 0.4488 - val_accuracy: 0.7825\n",
      "Epoch 62/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4646 - accuracy: 0.7685 - val_loss: 0.4406 - val_accuracy: 0.7825\n",
      "Epoch 63/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4601 - accuracy: 0.7688 - val_loss: 0.4363 - val_accuracy: 0.7825\n",
      "Epoch 64/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4532 - accuracy: 0.7685 - val_loss: 0.4276 - val_accuracy: 0.7825\n",
      "Epoch 65/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4460 - accuracy: 0.7685 - val_loss: 0.4198 - val_accuracy: 0.7825\n",
      "Epoch 66/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4469 - accuracy: 0.7653 - val_loss: 0.4239 - val_accuracy: 0.7825\n",
      "Epoch 67/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 2.6484 - accuracy: 0.6615 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 68/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 69/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 70/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 71/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 72/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 73/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 74/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 75/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 76/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 77/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 78/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 79/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 80/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 81/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 82/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 83/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 84/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 85/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 85: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 11.6237 - accuracy: 0.2377\n",
      "[CV] END activation_function=sigmoid, n_hidden=4, n_neurons=55; total time=  43.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5663 - accuracy: 0.7915 - val_loss: 0.5045 - val_accuracy: 0.7825\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.8069 - val_loss: 0.4798 - val_accuracy: 0.7962\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 5.7158 - accuracy: 0.5450 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 22: early stopping\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 11.7190 - accuracy: 0.2315\n",
      "[CV] END .activation_function=relu, n_hidden=3, n_neurons=23; total time=  11.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 2ms/step - loss: 0.8276 - accuracy: 0.7401 - val_loss: 0.5558 - val_accuracy: 0.7738\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.7997 - val_loss: 11.5918 - val_accuracy: 0.2325\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 1.3782 - accuracy: 0.7000 - val_loss: 0.4505 - val_accuracy: 0.8213\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8229 - val_loss: 0.4493 - val_accuracy: 0.8263\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.8336 - val_loss: 0.4267 - val_accuracy: 0.8275\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8376 - val_loss: 0.4113 - val_accuracy: 0.8350\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8382 - val_loss: 0.4051 - val_accuracy: 0.8363\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8386 - val_loss: 0.4029 - val_accuracy: 0.8363\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8403 - val_loss: 0.3980 - val_accuracy: 0.8250\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8415 - val_loss: 0.3956 - val_accuracy: 0.8263\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8429 - val_loss: 0.3955 - val_accuracy: 0.8250\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8442 - val_loss: 0.3935 - val_accuracy: 0.8250\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8410 - val_loss: 0.3941 - val_accuracy: 0.8300\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8424 - val_loss: 0.3929 - val_accuracy: 0.8250\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8447 - val_loss: 0.3903 - val_accuracy: 0.8263\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8474 - val_loss: 0.3903 - val_accuracy: 0.8250\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8478 - val_loss: 0.3925 - val_accuracy: 0.8250\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8431 - val_loss: 0.3952 - val_accuracy: 0.8363\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8469 - val_loss: 0.4097 - val_accuracy: 0.8288\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8490 - val_loss: 0.4039 - val_accuracy: 0.8325\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8504 - val_loss: 0.3874 - val_accuracy: 0.8238\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8497 - val_loss: 0.3860 - val_accuracy: 0.8288\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3523 - accuracy: 0.8497 - val_loss: 0.3868 - val_accuracy: 0.8325\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8494 - val_loss: 0.3871 - val_accuracy: 0.8263\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3483 - accuracy: 0.8501 - val_loss: 0.3883 - val_accuracy: 0.8263\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8494 - val_loss: 0.3902 - val_accuracy: 0.8325\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3469 - accuracy: 0.8507 - val_loss: 0.3867 - val_accuracy: 0.8275\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3454 - accuracy: 0.8499 - val_loss: 0.3855 - val_accuracy: 0.8288\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8510 - val_loss: 0.3891 - val_accuracy: 0.8275\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8514 - val_loss: 0.3872 - val_accuracy: 0.8275\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.8511 - val_loss: 0.3865 - val_accuracy: 0.8263\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8515 - val_loss: 0.3882 - val_accuracy: 0.8275\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3413 - accuracy: 0.8528 - val_loss: 0.3905 - val_accuracy: 0.8288\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8532 - val_loss: 0.3875 - val_accuracy: 0.8300\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8531 - val_loss: 0.3875 - val_accuracy: 0.8300\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8192 - val_loss: 0.5564 - val_accuracy: 0.8100\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8429 - val_loss: 0.3939 - val_accuracy: 0.8375\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.8035 - val_loss: 0.4108 - val_accuracy: 0.8213\n",
      "Epoch 39/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8428 - val_loss: 0.3922 - val_accuracy: 0.8288\n",
      "Epoch 40/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8487 - val_loss: 0.3965 - val_accuracy: 0.8388\n",
      "Epoch 41/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8503 - val_loss: 0.3885 - val_accuracy: 0.8338\n",
      "Epoch 42/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3493 - accuracy: 0.8504 - val_loss: 0.3900 - val_accuracy: 0.8350\n",
      "Epoch 43/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3459 - accuracy: 0.8511 - val_loss: 0.4081 - val_accuracy: 0.8313\n",
      "Epoch 44/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.8522 - val_loss: 0.4078 - val_accuracy: 0.8338\n",
      "Epoch 45/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8518 - val_loss: 0.4166 - val_accuracy: 0.8375\n",
      "Epoch 46/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8522 - val_loss: 0.3886 - val_accuracy: 0.8363\n",
      "Epoch 47/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8519 - val_loss: 0.4014 - val_accuracy: 0.8338\n",
      "Epoch 48/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8537 - val_loss: 0.4034 - val_accuracy: 0.8325\n",
      "Epoch 48: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3793 - accuracy: 0.8465\n",
      "[CV] END .activation_function=relu, n_hidden=3, n_neurons=23; total time=  23.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5356 - accuracy: 0.7792 - val_loss: 0.4481 - val_accuracy: 0.8000\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.8090 - val_loss: 0.4245 - val_accuracy: 0.8125\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8112 - val_loss: 0.4415 - val_accuracy: 0.8138\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8214 - val_loss: 0.4144 - val_accuracy: 0.8213\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.8115 - val_loss: 0.6027 - val_accuracy: 0.6913\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8204 - val_loss: 0.4417 - val_accuracy: 0.8238\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8314 - val_loss: 0.3837 - val_accuracy: 0.8275\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.7214 - accuracy: 0.7969 - val_loss: 2.9891 - val_accuracy: 0.4300\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.8242 - val_loss: 0.4033 - val_accuracy: 0.8325\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4085 - accuracy: 0.8375 - val_loss: 0.3983 - val_accuracy: 0.8350\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8363 - val_loss: 0.3896 - val_accuracy: 0.8313\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3857 - accuracy: 0.8414 - val_loss: 0.3744 - val_accuracy: 0.8438\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8424 - val_loss: 0.3695 - val_accuracy: 0.8363\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8438 - val_loss: 0.3785 - val_accuracy: 0.8350\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8436 - val_loss: 0.3775 - val_accuracy: 0.8388\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8449 - val_loss: 0.3800 - val_accuracy: 0.8413\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8457 - val_loss: 0.3889 - val_accuracy: 0.8425\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8456 - val_loss: 0.3638 - val_accuracy: 0.8425\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8464 - val_loss: 0.3813 - val_accuracy: 0.8400\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8472 - val_loss: 0.3645 - val_accuracy: 0.8450\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3499 - accuracy: 0.8497 - val_loss: 0.3900 - val_accuracy: 0.8425\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8499 - val_loss: 0.3747 - val_accuracy: 0.8450\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3455 - accuracy: 0.8486 - val_loss: 0.3811 - val_accuracy: 0.8438\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.8500 - val_loss: 0.3750 - val_accuracy: 0.8450\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3420 - accuracy: 0.8507 - val_loss: 0.4149 - val_accuracy: 0.8450\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8511 - val_loss: 0.3730 - val_accuracy: 0.8462\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3388 - accuracy: 0.8511 - val_loss: 0.3779 - val_accuracy: 0.8462\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3387 - accuracy: 0.8514 - val_loss: 0.3729 - val_accuracy: 0.8512\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3371 - accuracy: 0.8526 - val_loss: 0.4265 - val_accuracy: 0.8512\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8526 - val_loss: 0.4124 - val_accuracy: 0.8525\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8540 - val_loss: 0.3965 - val_accuracy: 0.8525\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8529 - val_loss: 0.3723 - val_accuracy: 0.8450\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8529 - val_loss: 0.4120 - val_accuracy: 0.8512\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8526 - val_loss: 0.4115 - val_accuracy: 0.8550\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3304 - accuracy: 0.8550 - val_loss: 0.4141 - val_accuracy: 0.8537\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8546 - val_loss: 0.3928 - val_accuracy: 0.8537\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8546 - val_loss: 0.4100 - val_accuracy: 0.8512\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8558 - val_loss: 0.4094 - val_accuracy: 0.8512\n",
      "Epoch 38: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8432\n",
      "[CV] END .activation_function=relu, n_hidden=3, n_neurons=23; total time=  21.3s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 1.3966 - accuracy: 0.7797 - val_loss: 7.0281 - val_accuracy: 0.4900\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 5.1134 - accuracy: 0.6154 - val_loss: 2.3844 - val_accuracy: 0.8025\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.0653 - accuracy: 0.8112 - val_loss: 2.0491 - val_accuracy: 0.8100\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.8751 - accuracy: 0.7611 - val_loss: 2.3037 - val_accuracy: 0.7950\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.0396 - accuracy: 0.8106 - val_loss: 2.2232 - val_accuracy: 0.8087\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 1.5281 - accuracy: 0.8285 - val_loss: 1.6345 - val_accuracy: 0.7825\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.9749 - accuracy: 0.8211 - val_loss: 0.6291 - val_accuracy: 0.7850\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 6.3423 - accuracy: 0.5601 - val_loss: 3.9684 - val_accuracy: 0.7375\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.9027 - accuracy: 0.8083 - val_loss: 2.9824 - val_accuracy: 0.8025\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 7.3872 - accuracy: 0.5153 - val_loss: 7.3335 - val_accuracy: 0.5200\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 7.1063 - accuracy: 0.5340 - val_loss: 7.1821 - val_accuracy: 0.5300\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 6.5675 - accuracy: 0.5696 - val_loss: 6.4356 - val_accuracy: 0.5775\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 5.6426 - accuracy: 0.6296 - val_loss: 3.9743 - val_accuracy: 0.7400\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.9289 - accuracy: 0.7424 - val_loss: 3.9052 - val_accuracy: 0.7400\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.7867 - accuracy: 0.7521 - val_loss: 3.7862 - val_accuracy: 0.7513\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6838 - accuracy: 0.7582 - val_loss: 3.6903 - val_accuracy: 0.7588\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.7059 - accuracy: 0.7565 - val_loss: 3.7850 - val_accuracy: 0.7525\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6674 - accuracy: 0.7590 - val_loss: 3.5385 - val_accuracy: 0.7675\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.4297 - accuracy: 0.7753 - val_loss: 3.6165 - val_accuracy: 0.7625\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.9551 - accuracy: 0.7407 - val_loss: 5.2142 - val_accuracy: 0.6575\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 5.0055 - accuracy: 0.6717 - val_loss: 4.8715 - val_accuracy: 0.6800\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 4.7873 - accuracy: 0.6862 - val_loss: 4.7943 - val_accuracy: 0.6862\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 4.7531 - accuracy: 0.6888 - val_loss: 4.9085 - val_accuracy: 0.6787\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 4.1289 - accuracy: 0.7290 - val_loss: 4.0689 - val_accuracy: 0.7337\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.8874 - accuracy: 0.7450 - val_loss: 4.0316 - val_accuracy: 0.7362\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.7106 - accuracy: 0.7565 - val_loss: 3.5257 - val_accuracy: 0.7663\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.4956 - accuracy: 0.7713 - val_loss: 3.5194 - val_accuracy: 0.7700\n",
      "Epoch 27: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.5038 - accuracy: 0.7700\n",
      "[CV] END ..activation_function=elu, n_hidden=2, n_neurons=71; total time=  13.9s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 2.8930 - accuracy: 0.7281 - val_loss: 3.5635 - val_accuracy: 0.7563\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 4.5988 - accuracy: 0.6942 - val_loss: 3.5914 - val_accuracy: 0.7650\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6740 - accuracy: 0.7614 - val_loss: 3.6069 - val_accuracy: 0.7650\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6680 - accuracy: 0.7617 - val_loss: 3.6060 - val_accuracy: 0.7650\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.6619 - accuracy: 0.7621 - val_loss: 3.6071 - val_accuracy: 0.7650\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.4188 - accuracy: 0.7743 - val_loss: 3.2018 - val_accuracy: 0.7912\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.9004 - accuracy: 0.7419 - val_loss: 3.7248 - val_accuracy: 0.7550\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.6399 - accuracy: 0.7625 - val_loss: 3.5861 - val_accuracy: 0.7675\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.6112 - accuracy: 0.7654 - val_loss: 3.5674 - val_accuracy: 0.7688\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5959 - accuracy: 0.7664 - val_loss: 3.5505 - val_accuracy: 0.7688\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5600 - accuracy: 0.7679 - val_loss: 3.4324 - val_accuracy: 0.7775\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5029 - accuracy: 0.7713 - val_loss: 3.4003 - val_accuracy: 0.7763\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.4634 - accuracy: 0.7746 - val_loss: 3.3784 - val_accuracy: 0.7788\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.4237 - accuracy: 0.7747 - val_loss: 3.4321 - val_accuracy: 0.7775\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5717 - accuracy: 0.7678 - val_loss: 3.4710 - val_accuracy: 0.7750\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.4576 - accuracy: 0.7733 - val_loss: 3.2449 - val_accuracy: 0.7875\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.4384 - accuracy: 0.7758 - val_loss: 3.3949 - val_accuracy: 0.7800\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.4407 - accuracy: 0.7757 - val_loss: 3.3240 - val_accuracy: 0.7812\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 3.3263 - accuracy: 0.7811 - val_loss: 3.2782 - val_accuracy: 0.7837\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.2567 - accuracy: 0.7865 - val_loss: 3.1745 - val_accuracy: 0.7875\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.2744 - accuracy: 0.7853 - val_loss: 3.2087 - val_accuracy: 0.7875\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.2515 - accuracy: 0.7865 - val_loss: 3.2249 - val_accuracy: 0.7862\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.1845 - accuracy: 0.7901 - val_loss: 3.1314 - val_accuracy: 0.7912\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.1377 - accuracy: 0.7932 - val_loss: 3.2598 - val_accuracy: 0.7825\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.1762 - accuracy: 0.7908 - val_loss: 3.1221 - val_accuracy: 0.7937\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.1025 - accuracy: 0.7964 - val_loss: 3.0724 - val_accuracy: 0.7950\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.0435 - accuracy: 0.8000 - val_loss: 3.0165 - val_accuracy: 0.7987\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 2.9670 - accuracy: 0.8046 - val_loss: 2.9397 - val_accuracy: 0.8025\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.0478 - accuracy: 0.8006 - val_loss: 3.4578 - val_accuracy: 0.7738\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.4948 - accuracy: 0.7729 - val_loss: 3.4546 - val_accuracy: 0.7750\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.4553 - accuracy: 0.7750 - val_loss: 3.3542 - val_accuracy: 0.7812\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.3862 - accuracy: 0.7790 - val_loss: 3.3728 - val_accuracy: 0.7812\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.3651 - accuracy: 0.7810 - val_loss: 3.2986 - val_accuracy: 0.7837\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.3513 - accuracy: 0.7812 - val_loss: 3.3217 - val_accuracy: 0.7825\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.3171 - accuracy: 0.7836 - val_loss: 3.3159 - val_accuracy: 0.7837\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.2923 - accuracy: 0.7857 - val_loss: 3.1796 - val_accuracy: 0.7937\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.2227 - accuracy: 0.7896 - val_loss: 3.2178 - val_accuracy: 0.7912\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.1191 - accuracy: 0.7961 - val_loss: 2.9858 - val_accuracy: 0.8050\n",
      "Epoch 39/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.0171 - accuracy: 0.8015 - val_loss: 2.9517 - val_accuracy: 0.8050\n",
      "Epoch 40/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.0025 - accuracy: 0.8019 - val_loss: 3.0470 - val_accuracy: 0.7987\n",
      "Epoch 41/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.9963 - accuracy: 0.8039 - val_loss: 2.9685 - val_accuracy: 0.8062\n",
      "Epoch 42/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.3187 - accuracy: 0.7819 - val_loss: 3.4073 - val_accuracy: 0.7738\n",
      "Epoch 43/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.1869 - accuracy: 0.7897 - val_loss: 3.2330 - val_accuracy: 0.7875\n",
      "Epoch 44/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.1025 - accuracy: 0.7968 - val_loss: 3.2008 - val_accuracy: 0.7875\n",
      "Epoch 45/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.0612 - accuracy: 0.7990 - val_loss: 2.8982 - val_accuracy: 0.8062\n",
      "Epoch 46/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.8961 - accuracy: 0.8094 - val_loss: 2.8471 - val_accuracy: 0.8112\n",
      "Epoch 47/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.8772 - accuracy: 0.8104 - val_loss: 2.8496 - val_accuracy: 0.8112\n",
      "Epoch 48/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.9557 - accuracy: 0.8056 - val_loss: 3.4858 - val_accuracy: 0.7675\n",
      "Epoch 49/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.2603 - accuracy: 0.7854 - val_loss: 3.1317 - val_accuracy: 0.7950\n",
      "Epoch 50/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.9221 - accuracy: 0.8074 - val_loss: 2.8703 - val_accuracy: 0.8112\n",
      "Epoch 51/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.8270 - accuracy: 0.8143 - val_loss: 2.8501 - val_accuracy: 0.8100\n",
      "Epoch 52/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.8174 - accuracy: 0.8150 - val_loss: 2.8440 - val_accuracy: 0.8150\n",
      "Epoch 53/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.7790 - accuracy: 0.8172 - val_loss: 2.9053 - val_accuracy: 0.8087\n",
      "Epoch 54/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 2.7883 - accuracy: 0.8171 - val_loss: 2.8714 - val_accuracy: 0.8087\n",
      "Epoch 55/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.8222 - accuracy: 0.8146 - val_loss: 2.9887 - val_accuracy: 0.8037\n",
      "Epoch 56/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.8363 - accuracy: 0.8140 - val_loss: 3.0700 - val_accuracy: 0.7962\n",
      "Epoch 57/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.8645 - accuracy: 0.8125 - val_loss: 2.9531 - val_accuracy: 0.8050\n",
      "Epoch 58/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.8358 - accuracy: 0.8139 - val_loss: 3.0443 - val_accuracy: 0.8025\n",
      "Epoch 59/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.8463 - accuracy: 0.8146 - val_loss: 2.9741 - val_accuracy: 0.8037\n",
      "Epoch 60/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.8375 - accuracy: 0.8149 - val_loss: 2.9476 - val_accuracy: 0.8087\n",
      "Epoch 61/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 2.7144 - accuracy: 0.8222 - val_loss: 2.7700 - val_accuracy: 0.8200\n",
      "Epoch 62/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.6339 - accuracy: 0.8263 - val_loss: 2.6942 - val_accuracy: 0.8225\n",
      "Epoch 63/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.6514 - accuracy: 0.8253 - val_loss: 2.6556 - val_accuracy: 0.8263\n",
      "Epoch 64/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.6100 - accuracy: 0.8285 - val_loss: 2.6864 - val_accuracy: 0.8225\n",
      "Epoch 65/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 2.5914 - accuracy: 0.8297 - val_loss: 2.7934 - val_accuracy: 0.8138\n",
      "Epoch 66/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 2.6469 - accuracy: 0.8256 - val_loss: 2.8597 - val_accuracy: 0.8112\n",
      "Epoch 67/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.7358 - accuracy: 0.8203 - val_loss: 2.9855 - val_accuracy: 0.8050\n",
      "Epoch 68/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.7881 - accuracy: 0.8179 - val_loss: 2.9113 - val_accuracy: 0.8100\n",
      "Epoch 69/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 2.7324 - accuracy: 0.8207 - val_loss: 2.7743 - val_accuracy: 0.8175\n",
      "Epoch 70/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.7777 - accuracy: 0.8169 - val_loss: 3.0409 - val_accuracy: 0.7987\n",
      "Epoch 71/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.8069 - accuracy: 0.8150 - val_loss: 2.9784 - val_accuracy: 0.8050\n",
      "Epoch 72/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.8100 - accuracy: 0.8154 - val_loss: 2.8496 - val_accuracy: 0.8112\n",
      "Epoch 73/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.6918 - accuracy: 0.8226 - val_loss: 2.7147 - val_accuracy: 0.8200\n",
      "Epoch 74/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.5576 - accuracy: 0.8315 - val_loss: 2.5835 - val_accuracy: 0.8275\n",
      "Epoch 75/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.5040 - accuracy: 0.8353 - val_loss: 2.6206 - val_accuracy: 0.8263\n",
      "Epoch 76/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.6004 - accuracy: 0.8300 - val_loss: 2.6746 - val_accuracy: 0.8238\n",
      "Epoch 77/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.5184 - accuracy: 0.8346 - val_loss: 2.9365 - val_accuracy: 0.8050\n",
      "Epoch 78/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.4748 - accuracy: 0.8374 - val_loss: 2.7891 - val_accuracy: 0.8163\n",
      "Epoch 79/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.4987 - accuracy: 0.8358 - val_loss: 2.7542 - val_accuracy: 0.8188\n",
      "Epoch 80/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.5219 - accuracy: 0.8349 - val_loss: 2.6974 - val_accuracy: 0.8238\n",
      "Epoch 81/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.6411 - accuracy: 0.8268 - val_loss: 2.6076 - val_accuracy: 0.8263\n",
      "Epoch 82/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 2.5552 - accuracy: 0.8326 - val_loss: 2.6387 - val_accuracy: 0.8275\n",
      "Epoch 83/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 2.9699 - accuracy: 0.8060 - val_loss: 3.6834 - val_accuracy: 0.7600\n",
      "Epoch 84/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.6168 - accuracy: 0.7635 - val_loss: 3.6638 - val_accuracy: 0.7613\n",
      "Epoch 85/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6114 - accuracy: 0.7644 - val_loss: 3.6439 - val_accuracy: 0.7625\n",
      "Epoch 86/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6045 - accuracy: 0.7651 - val_loss: 3.6443 - val_accuracy: 0.7625\n",
      "Epoch 87/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.7359 - accuracy: 0.7554 - val_loss: 4.1008 - val_accuracy: 0.7312\n",
      "Epoch 88/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.7124 - accuracy: 0.7578 - val_loss: 3.5853 - val_accuracy: 0.7663\n",
      "Epoch 89/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5741 - accuracy: 0.7671 - val_loss: 3.5308 - val_accuracy: 0.7688\n",
      "Epoch 90/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5383 - accuracy: 0.7690 - val_loss: 3.5741 - val_accuracy: 0.7663\n",
      "Epoch 91/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.4740 - accuracy: 0.7736 - val_loss: 3.5100 - val_accuracy: 0.7713\n",
      "Epoch 92/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.4722 - accuracy: 0.7739 - val_loss: 3.4727 - val_accuracy: 0.7725\n",
      "Epoch 93/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.4901 - accuracy: 0.7729 - val_loss: 3.5170 - val_accuracy: 0.7700\n",
      "Epoch 94/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5258 - accuracy: 0.7699 - val_loss: 3.5673 - val_accuracy: 0.7675\n",
      "Epoch 94: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.4635 - accuracy: 0.7747\n",
      "[CV] END ..activation_function=elu, n_hidden=2, n_neurons=71; total time= 1.4min\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 1.3723 - accuracy: 0.7986 - val_loss: 1.9865 - val_accuracy: 0.8225\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.8346 - accuracy: 0.7778 - val_loss: 2.8098 - val_accuracy: 0.7738\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.7266 - accuracy: 0.7947 - val_loss: 3.1393 - val_accuracy: 0.7900\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.2245 - accuracy: 0.7821 - val_loss: 2.8063 - val_accuracy: 0.8025\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 2.6960 - accuracy: 0.7997 - val_loss: 2.1598 - val_accuracy: 0.8363\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 2.7844 - accuracy: 0.7983 - val_loss: 2.9037 - val_accuracy: 0.7975\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.7328 - accuracy: 0.8003 - val_loss: 2.3766 - val_accuracy: 0.8250\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.2728 - accuracy: 0.8276 - val_loss: 2.3486 - val_accuracy: 0.8300\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.1785 - accuracy: 0.8346 - val_loss: 2.2690 - val_accuracy: 0.8350\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.2949 - accuracy: 0.7689 - val_loss: 3.7337 - val_accuracy: 0.7475\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.3411 - accuracy: 0.7676 - val_loss: 2.8805 - val_accuracy: 0.7937\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.5922 - accuracy: 0.8122 - val_loss: 2.5698 - val_accuracy: 0.8163\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 2.4133 - accuracy: 0.8240 - val_loss: 2.3676 - val_accuracy: 0.8338\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 2.2976 - accuracy: 0.8325 - val_loss: 2.5940 - val_accuracy: 0.8175\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 2.5972 - accuracy: 0.8169 - val_loss: 2.3015 - val_accuracy: 0.8313\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 2.1937 - accuracy: 0.8339 - val_loss: 2.2280 - val_accuracy: 0.8425\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 6.1442 - accuracy: 0.5868 - val_loss: 5.7811 - val_accuracy: 0.6200\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 5.4834 - accuracy: 0.6392 - val_loss: 4.7153 - val_accuracy: 0.6888\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 4.6353 - accuracy: 0.6936 - val_loss: 4.0779 - val_accuracy: 0.7337\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.8826 - accuracy: 0.7453 - val_loss: 3.6424 - val_accuracy: 0.7613\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.6037 - accuracy: 0.7640 - val_loss: 3.4140 - val_accuracy: 0.7763\n",
      "Epoch 21: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.6806 - accuracy: 0.7590\n",
      "[CV] END ..activation_function=elu, n_hidden=2, n_neurons=71; total time=  11.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 2s 6ms/step - loss: 0.4815 - accuracy: 0.7817 - val_loss: 0.4465 - val_accuracy: 0.7962\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7974 - val_loss: 0.4252 - val_accuracy: 0.7975\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4077 - accuracy: 0.8182 - val_loss: 0.4291 - val_accuracy: 0.8163\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3998 - accuracy: 0.8238 - val_loss: 0.4344 - val_accuracy: 0.8213\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3930 - accuracy: 0.8289 - val_loss: 0.4498 - val_accuracy: 0.8175\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3858 - accuracy: 0.8293 - val_loss: 0.4528 - val_accuracy: 0.8325\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3873 - accuracy: 0.8300 - val_loss: 0.4641 - val_accuracy: 0.8213\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8346 - val_loss: 0.4164 - val_accuracy: 0.8325\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3824 - accuracy: 0.8349 - val_loss: 0.4283 - val_accuracy: 0.8288\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8351 - val_loss: 0.4169 - val_accuracy: 0.8263\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3689 - accuracy: 0.8358 - val_loss: 0.4168 - val_accuracy: 0.8225\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 2.3197 - accuracy: 0.7344 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.6911 - accuracy: 0.2333 - val_loss: 11.7038 - val_accuracy: 0.2325\n",
      "Epoch 28: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 11.7190 - accuracy: 0.2315\n",
      "[CV] END .activation_function=relu, n_hidden=5, n_neurons=34; total time=  16.0s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4975 - accuracy: 0.7742 - val_loss: 0.4491 - val_accuracy: 0.7912\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4357 - accuracy: 0.8206 - val_loss: 0.4179 - val_accuracy: 0.8188\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4082 - accuracy: 0.8325 - val_loss: 0.4089 - val_accuracy: 0.8188\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4031 - accuracy: 0.8361 - val_loss: 0.4082 - val_accuracy: 0.8238\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3948 - accuracy: 0.8397 - val_loss: 0.4217 - val_accuracy: 0.8175\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8399 - val_loss: 0.4004 - val_accuracy: 0.8250\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8408 - val_loss: 0.4116 - val_accuracy: 0.8175\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8431 - val_loss: 0.4086 - val_accuracy: 0.8200\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3788 - accuracy: 0.8417 - val_loss: 0.4071 - val_accuracy: 0.8200\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8436 - val_loss: 0.4048 - val_accuracy: 0.8213\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8433 - val_loss: 0.4039 - val_accuracy: 0.8225\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3709 - accuracy: 0.8435 - val_loss: 0.4038 - val_accuracy: 0.8213\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3724 - accuracy: 0.8435 - val_loss: 0.4065 - val_accuracy: 0.8300\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3681 - accuracy: 0.8454 - val_loss: 0.4035 - val_accuracy: 0.8250\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8451 - val_loss: 0.4028 - val_accuracy: 0.8275\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3657 - accuracy: 0.8471 - val_loss: 0.4021 - val_accuracy: 0.8250\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8482 - val_loss: 0.4053 - val_accuracy: 0.8200\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8483 - val_loss: 0.3991 - val_accuracy: 0.8238\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3580 - accuracy: 0.8487 - val_loss: 0.4176 - val_accuracy: 0.8288\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3597 - accuracy: 0.8474 - val_loss: 0.4258 - val_accuracy: 0.8263\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3567 - accuracy: 0.8474 - val_loss: 0.4031 - val_accuracy: 0.8213\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3562 - accuracy: 0.8485 - val_loss: 0.3978 - val_accuracy: 0.8300\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8475 - val_loss: 0.4000 - val_accuracy: 0.8288\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8487 - val_loss: 0.4027 - val_accuracy: 0.8325\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3515 - accuracy: 0.8494 - val_loss: 0.4280 - val_accuracy: 0.8313\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3492 - accuracy: 0.8500 - val_loss: 0.4314 - val_accuracy: 0.8313\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3553 - accuracy: 0.8496 - val_loss: 0.4009 - val_accuracy: 0.8300\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3455 - accuracy: 0.8496 - val_loss: 0.4026 - val_accuracy: 0.8300\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3448 - accuracy: 0.8515 - val_loss: 0.4277 - val_accuracy: 0.8288\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3742 - accuracy: 0.8469 - val_loss: 0.4165 - val_accuracy: 0.8338\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3988 - accuracy: 0.8451 - val_loss: 0.4206 - val_accuracy: 0.8338\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3540 - accuracy: 0.8514 - val_loss: 0.4379 - val_accuracy: 0.8250\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3515 - accuracy: 0.8512 - val_loss: 0.4382 - val_accuracy: 0.8288\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3477 - accuracy: 0.8489 - val_loss: 0.4292 - val_accuracy: 0.8338\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5237 - accuracy: 0.8268 - val_loss: 0.4054 - val_accuracy: 0.8300\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3563 - accuracy: 0.8531 - val_loss: 0.4489 - val_accuracy: 0.8325\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8494 - val_loss: 0.4145 - val_accuracy: 0.8275\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3460 - accuracy: 0.8511 - val_loss: 0.4291 - val_accuracy: 0.8300\n",
      "Epoch 39/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3462 - accuracy: 0.8507 - val_loss: 0.4167 - val_accuracy: 0.8288\n",
      "Epoch 40/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3404 - accuracy: 0.8518 - val_loss: 0.4747 - val_accuracy: 0.8325\n",
      "Epoch 41/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.8533 - val_loss: 0.4314 - val_accuracy: 0.8300\n",
      "Epoch 42/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3378 - accuracy: 0.8533 - val_loss: 0.4645 - val_accuracy: 0.8325\n",
      "Epoch 42: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8485\n",
      "[CV] END .activation_function=relu, n_hidden=5, n_neurons=34; total time=  22.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5575 - accuracy: 0.7942 - val_loss: 0.4051 - val_accuracy: 0.8213\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.8172 - val_loss: 0.3883 - val_accuracy: 0.8288\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.8176 - val_loss: 0.3891 - val_accuracy: 0.8313\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 2.8218 - accuracy: 0.7829 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.7685 - val_loss: 3.3549 - val_accuracy: 0.7825\n",
      "Epoch 22: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.6673 - accuracy: 0.7623\n",
      "[CV] END .activation_function=relu, n_hidden=5, n_neurons=34; total time=  21.3s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6945 - accuracy: 0.8000 - val_loss: 0.5477 - val_accuracy: 0.8050\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.8264 - val_loss: 0.5921 - val_accuracy: 0.8163\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.8211 - val_loss: 0.5433 - val_accuracy: 0.8062\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.8265 - val_loss: 0.5127 - val_accuracy: 0.8087\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8401 - val_loss: 0.5254 - val_accuracy: 0.8175\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.8329 - val_loss: 0.5426 - val_accuracy: 0.8163\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8433 - val_loss: 0.4626 - val_accuracy: 0.8163\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8456 - val_loss: 0.4657 - val_accuracy: 0.8238\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.3924 - accuracy: 0.8451 - val_loss: 0.4627 - val_accuracy: 0.8175\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.3881 - accuracy: 0.8461 - val_loss: 0.5043 - val_accuracy: 0.8188\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.3903 - accuracy: 0.8447 - val_loss: 0.4587 - val_accuracy: 0.8238\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.3822 - accuracy: 0.8475 - val_loss: 0.4841 - val_accuracy: 0.8250\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.3780 - accuracy: 0.8503 - val_loss: 0.4989 - val_accuracy: 0.8275\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3742 - accuracy: 0.8522 - val_loss: 0.5076 - val_accuracy: 0.8200\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3869 - accuracy: 0.8511 - val_loss: 1.8298 - val_accuracy: 0.7713\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8429 - val_loss: 0.4904 - val_accuracy: 0.8225\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8524 - val_loss: 0.5293 - val_accuracy: 0.8238\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8535 - val_loss: 0.5025 - val_accuracy: 0.8225\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8532 - val_loss: 0.4929 - val_accuracy: 0.8313\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8533 - val_loss: 0.5275 - val_accuracy: 0.8213\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8568 - val_loss: 0.5119 - val_accuracy: 0.8300\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3583 - accuracy: 0.8557 - val_loss: 0.5140 - val_accuracy: 0.8263\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3565 - accuracy: 0.8565 - val_loss: 0.5344 - val_accuracy: 0.8300\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3546 - accuracy: 0.8564 - val_loss: 0.5517 - val_accuracy: 0.8288\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8585 - val_loss: 0.5647 - val_accuracy: 0.8313\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8579 - val_loss: 0.6231 - val_accuracy: 0.8325\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3503 - accuracy: 0.8590 - val_loss: 0.5833 - val_accuracy: 0.8325\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3488 - accuracy: 0.8599 - val_loss: 0.5806 - val_accuracy: 0.8338\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8596 - val_loss: 0.6122 - val_accuracy: 0.8300\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8607 - val_loss: 0.6353 - val_accuracy: 0.8338\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3444 - accuracy: 0.8610 - val_loss: 0.6101 - val_accuracy: 0.8325\n",
      "Epoch 31: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.8475\n",
      "[CV] END .activation_function=relu, n_hidden=2, n_neurons=88; total time=  18.7s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 2.2633 - accuracy: 0.7421 - val_loss: 0.7010 - val_accuracy: 0.7975\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.9224 - accuracy: 0.7576 - val_loss: 0.6426 - val_accuracy: 0.8175\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5234 - accuracy: 0.8147 - val_loss: 0.6052 - val_accuracy: 0.8012\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5303 - accuracy: 0.8232 - val_loss: 0.5991 - val_accuracy: 0.8163\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.6333 - accuracy: 0.7857 - val_loss: 0.5566 - val_accuracy: 0.8150\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.8188 - val_loss: 0.4867 - val_accuracy: 0.8263\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8388 - val_loss: 0.4575 - val_accuracy: 0.8325\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8424 - val_loss: 0.4770 - val_accuracy: 0.8388\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4104 - accuracy: 0.8414 - val_loss: 0.4654 - val_accuracy: 0.8400\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 1.7649 - accuracy: 0.7460 - val_loss: 2.5335 - val_accuracy: 0.6650\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.7925 - accuracy: 0.7969 - val_loss: 0.5080 - val_accuracy: 0.8188\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4267 - accuracy: 0.8351 - val_loss: 0.4986 - val_accuracy: 0.8213\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4449 - accuracy: 0.8288 - val_loss: 0.4694 - val_accuracy: 0.8325\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4125 - accuracy: 0.8393 - val_loss: 0.4690 - val_accuracy: 0.8363\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3847 - accuracy: 0.8435 - val_loss: 0.4866 - val_accuracy: 0.8350\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3776 - accuracy: 0.8417 - val_loss: 0.4752 - val_accuracy: 0.8350\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3683 - accuracy: 0.8444 - val_loss: 0.5047 - val_accuracy: 0.8338\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8472 - val_loss: 0.5091 - val_accuracy: 0.8375\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8472 - val_loss: 0.5084 - val_accuracy: 0.8413\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8471 - val_loss: 0.5215 - val_accuracy: 0.8388\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8493 - val_loss: 0.5092 - val_accuracy: 0.8338\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8500 - val_loss: 0.5065 - val_accuracy: 0.8425\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3509 - accuracy: 0.8515 - val_loss: 0.5252 - val_accuracy: 0.8400\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3478 - accuracy: 0.8521 - val_loss: 0.5232 - val_accuracy: 0.8425\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3453 - accuracy: 0.8526 - val_loss: 0.5242 - val_accuracy: 0.8413\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8529 - val_loss: 0.5232 - val_accuracy: 0.8400\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3418 - accuracy: 0.8542 - val_loss: 0.5218 - val_accuracy: 0.8388\n",
      "Epoch 27: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.8475\n",
      "[CV] END .activation_function=relu, n_hidden=2, n_neurons=88; total time=  21.3s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5800 - accuracy: 0.7939 - val_loss: 0.4993 - val_accuracy: 0.8150\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.8215 - val_loss: 0.4256 - val_accuracy: 0.8300\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.8047 - val_loss: 0.3757 - val_accuracy: 0.8263\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.4184 - accuracy: 0.8351 - val_loss: 0.3679 - val_accuracy: 0.8375\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3968 - accuracy: 0.8400 - val_loss: 0.4007 - val_accuracy: 0.8313\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 7.5997 - accuracy: 0.4457 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 11.7186 - accuracy: 0.2315 - val_loss: 11.9325 - val_accuracy: 0.2175\n",
      "Epoch 24: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 11.6237 - accuracy: 0.2377\n",
      "[CV] END .activation_function=relu, n_hidden=2, n_neurons=88; total time=  13.0s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 3.5992 - accuracy: 0.7667 - val_loss: 3.5863 - val_accuracy: 0.7675\n",
      "Epoch 21: early stopping\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.5709 - accuracy: 0.7685\n",
      "[CV] END activation_function=sigmoid, n_hidden=5, n_neurons=35; total time=  12.0s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5462 - accuracy: 0.7651 - val_loss: 0.5421 - val_accuracy: 0.7675\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7651 - val_loss: 0.5436 - val_accuracy: 0.7675\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7651 - val_loss: 0.5420 - val_accuracy: 0.7675\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7651 - val_loss: 0.5451 - val_accuracy: 0.7675\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7651 - val_loss: 0.5461 - val_accuracy: 0.7675\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7651 - val_loss: 0.5442 - val_accuracy: 0.7675\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5458 - accuracy: 0.7651 - val_loss: 0.5422 - val_accuracy: 0.7675\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7651 - val_loss: 0.5444 - val_accuracy: 0.7675\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7651 - val_loss: 0.5420 - val_accuracy: 0.7675\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5467 - accuracy: 0.7651 - val_loss: 0.5467 - val_accuracy: 0.7675\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5461 - accuracy: 0.7651 - val_loss: 0.5444 - val_accuracy: 0.7675\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5468 - accuracy: 0.7651 - val_loss: 0.5424 - val_accuracy: 0.7675\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7651 - val_loss: 0.5476 - val_accuracy: 0.7675\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5465 - accuracy: 0.7651 - val_loss: 0.5419 - val_accuracy: 0.7675\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7651 - val_loss: 0.5421 - val_accuracy: 0.7675\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7651 - val_loss: 0.5447 - val_accuracy: 0.7675\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7651 - val_loss: 0.5478 - val_accuracy: 0.7675\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7651 - val_loss: 0.5466 - val_accuracy: 0.7675\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5472 - accuracy: 0.7651 - val_loss: 0.5418 - val_accuracy: 0.7675\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7651 - val_loss: 0.5421 - val_accuracy: 0.7675\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7651 - val_loss: 0.5470 - val_accuracy: 0.7675\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7651 - val_loss: 0.5440 - val_accuracy: 0.7675\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7651 - val_loss: 0.5420 - val_accuracy: 0.7675\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5463 - accuracy: 0.7651 - val_loss: 0.5422 - val_accuracy: 0.7675\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5466 - accuracy: 0.7651 - val_loss: 0.5424 - val_accuracy: 0.7675\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5463 - accuracy: 0.7651 - val_loss: 0.5480 - val_accuracy: 0.7675\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5468 - accuracy: 0.7651 - val_loss: 0.5419 - val_accuracy: 0.7675\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7651 - val_loss: 0.5417 - val_accuracy: 0.7675\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7651 - val_loss: 0.5440 - val_accuracy: 0.7675\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5447 - accuracy: 0.7651 - val_loss: 0.5443 - val_accuracy: 0.7675\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5463 - accuracy: 0.7651 - val_loss: 0.5420 - val_accuracy: 0.7675\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5459 - accuracy: 0.7651 - val_loss: 0.5429 - val_accuracy: 0.7675\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5470 - accuracy: 0.7651 - val_loss: 0.5418 - val_accuracy: 0.7675\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5459 - accuracy: 0.7651 - val_loss: 0.5421 - val_accuracy: 0.7675\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5461 - accuracy: 0.7651 - val_loss: 0.5417 - val_accuracy: 0.7675\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5453 - accuracy: 0.7651 - val_loss: 0.5418 - val_accuracy: 0.7675\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7651 - val_loss: 0.5418 - val_accuracy: 0.7675\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7651 - val_loss: 0.5418 - val_accuracy: 0.7675\n",
      "Epoch 39/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7651 - val_loss: 0.5420 - val_accuracy: 0.7675\n",
      "Epoch 40/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7651 - val_loss: 0.5421 - val_accuracy: 0.7675\n",
      "Epoch 41/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5452 - accuracy: 0.7651 - val_loss: 0.5428 - val_accuracy: 0.7675\n",
      "Epoch 42/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5462 - accuracy: 0.7651 - val_loss: 0.5421 - val_accuracy: 0.7675\n",
      "Epoch 43/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5459 - accuracy: 0.7651 - val_loss: 0.5437 - val_accuracy: 0.7675\n",
      "Epoch 44/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7651 - val_loss: 0.5443 - val_accuracy: 0.7675\n",
      "Epoch 45/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5462 - accuracy: 0.7651 - val_loss: 0.5415 - val_accuracy: 0.7675\n",
      "Epoch 46/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7651 - val_loss: 0.5418 - val_accuracy: 0.7675\n",
      "Epoch 47/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5461 - accuracy: 0.7651 - val_loss: 0.5432 - val_accuracy: 0.7675\n",
      "Epoch 48/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7651 - val_loss: 0.5419 - val_accuracy: 0.7675\n",
      "Epoch 49/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7651 - val_loss: 0.5416 - val_accuracy: 0.7675\n",
      "Epoch 50/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7651 - val_loss: 0.5435 - val_accuracy: 0.7675\n",
      "Epoch 51/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5460 - accuracy: 0.7651 - val_loss: 0.5419 - val_accuracy: 0.7675\n",
      "Epoch 52/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5461 - accuracy: 0.7651 - val_loss: 0.5414 - val_accuracy: 0.7675\n",
      "Epoch 53/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5461 - accuracy: 0.7651 - val_loss: 0.5417 - val_accuracy: 0.7675\n",
      "Epoch 54/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7651 - val_loss: 0.5424 - val_accuracy: 0.7675\n",
      "Epoch 55/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5455 - accuracy: 0.7651 - val_loss: 0.5413 - val_accuracy: 0.7675\n",
      "Epoch 56/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7651 - val_loss: 0.5432 - val_accuracy: 0.7675\n",
      "Epoch 57/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5459 - accuracy: 0.7651 - val_loss: 0.5452 - val_accuracy: 0.7675\n",
      "Epoch 58/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5460 - accuracy: 0.7651 - val_loss: 0.5414 - val_accuracy: 0.7675\n",
      "Epoch 59/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7651 - val_loss: 0.5452 - val_accuracy: 0.7675\n",
      "Epoch 60/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7651 - val_loss: 0.5412 - val_accuracy: 0.7675\n",
      "Epoch 61/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5462 - accuracy: 0.7651 - val_loss: 0.5416 - val_accuracy: 0.7675\n",
      "Epoch 62/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7651 - val_loss: 0.5414 - val_accuracy: 0.7675\n",
      "Epoch 63/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.7651 - val_loss: 0.5417 - val_accuracy: 0.7675\n",
      "Epoch 64/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7651 - val_loss: 0.5413 - val_accuracy: 0.7675\n",
      "Epoch 65/100\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5447 - accuracy: 0.7651 - val_loss: 0.5415 - val_accuracy: 0.7675\n",
      "Epoch 66/100\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.5455 - accuracy: 0.7651 - val_loss: 0.5411 - val_accuracy: 0.7675\n",
      "Epoch 67/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5456 - accuracy: 0.7651 - val_loss: 0.5414 - val_accuracy: 0.7675\n",
      "Epoch 68/100\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.5452 - accuracy: 0.7651 - val_loss: 0.5449 - val_accuracy: 0.7675\n",
      "Epoch 69/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5457 - accuracy: 0.7651 - val_loss: 0.5428 - val_accuracy: 0.7675\n",
      "Epoch 70/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5464 - accuracy: 0.7651 - val_loss: 0.5411 - val_accuracy: 0.7675\n",
      "Epoch 71/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5447 - accuracy: 0.7651 - val_loss: 0.5417 - val_accuracy: 0.7675\n",
      "Epoch 72/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7651 - val_loss: 0.5428 - val_accuracy: 0.7675\n",
      "Epoch 73/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5451 - accuracy: 0.7651 - val_loss: 0.5425 - val_accuracy: 0.7675\n",
      "Epoch 74/100\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.5446 - accuracy: 0.7651 - val_loss: 0.5588 - val_accuracy: 0.7675\n",
      "Epoch 75/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5454 - accuracy: 0.7651 - val_loss: 0.5437 - val_accuracy: 0.7675\n",
      "Epoch 76/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5442 - accuracy: 0.7651 - val_loss: 0.5464 - val_accuracy: 0.7675\n",
      "Epoch 77/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5458 - accuracy: 0.7651 - val_loss: 0.5411 - val_accuracy: 0.7675\n",
      "Epoch 78/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5448 - accuracy: 0.7651 - val_loss: 0.5421 - val_accuracy: 0.7675\n",
      "Epoch 79/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.7651 - val_loss: 0.5424 - val_accuracy: 0.7675\n",
      "Epoch 80/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5450 - accuracy: 0.7651 - val_loss: 0.5441 - val_accuracy: 0.7675\n",
      "Epoch 81/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5454 - accuracy: 0.7651 - val_loss: 0.5411 - val_accuracy: 0.7675\n",
      "Epoch 82/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7651 - val_loss: 0.5454 - val_accuracy: 0.7675\n",
      "Epoch 83/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5449 - accuracy: 0.7651 - val_loss: 0.5440 - val_accuracy: 0.7675\n",
      "Epoch 84/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5450 - accuracy: 0.7651 - val_loss: 0.5409 - val_accuracy: 0.7675\n",
      "Epoch 85/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.7651 - val_loss: 0.5410 - val_accuracy: 0.7675\n",
      "Epoch 86/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5457 - accuracy: 0.7651 - val_loss: 0.5421 - val_accuracy: 0.7675\n",
      "Epoch 87/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7651 - val_loss: 0.5419 - val_accuracy: 0.7675\n",
      "Epoch 88/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5449 - accuracy: 0.7651 - val_loss: 0.5420 - val_accuracy: 0.7675\n",
      "Epoch 89/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5452 - accuracy: 0.7651 - val_loss: 0.5410 - val_accuracy: 0.7675\n",
      "Epoch 90/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7651 - val_loss: 0.5412 - val_accuracy: 0.7675\n",
      "Epoch 91/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5458 - accuracy: 0.7651 - val_loss: 0.5454 - val_accuracy: 0.7675\n",
      "Epoch 92/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7651 - val_loss: 0.5416 - val_accuracy: 0.7675\n",
      "Epoch 93/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7651 - val_loss: 0.5458 - val_accuracy: 0.7675\n",
      "Epoch 94/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5446 - accuracy: 0.7651 - val_loss: 0.5404 - val_accuracy: 0.7675\n",
      "Epoch 95/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7651 - val_loss: 0.5406 - val_accuracy: 0.7675\n",
      "Epoch 96/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5450 - accuracy: 0.7651 - val_loss: 0.5448 - val_accuracy: 0.7675\n",
      "Epoch 97/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7651 - val_loss: 0.5408 - val_accuracy: 0.7675\n",
      "Epoch 98/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7651 - val_loss: 0.5404 - val_accuracy: 0.7675\n",
      "Epoch 99/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7651 - val_loss: 0.5403 - val_accuracy: 0.7675\n",
      "Epoch 100/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.7651 - val_loss: 0.5442 - val_accuracy: 0.7675\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7713\n",
      "[CV] END activation_function=sigmoid, n_hidden=5, n_neurons=35; total time= 1.4min\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5424 - accuracy: 0.7685 - val_loss: 0.5239 - val_accuracy: 0.7825\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5426 - accuracy: 0.7685 - val_loss: 0.5249 - val_accuracy: 0.7825\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5429 - accuracy: 0.7685 - val_loss: 0.5276 - val_accuracy: 0.7825\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7685 - val_loss: 0.5323 - val_accuracy: 0.7825\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7685 - val_loss: 0.5261 - val_accuracy: 0.7825\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7685 - val_loss: 0.5233 - val_accuracy: 0.7825\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7685 - val_loss: 0.5249 - val_accuracy: 0.7825\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7685 - val_loss: 0.5275 - val_accuracy: 0.7825\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.7685 - val_loss: 0.5242 - val_accuracy: 0.7825\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7685 - val_loss: 0.5234 - val_accuracy: 0.7825\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7685 - val_loss: 0.5273 - val_accuracy: 0.7825\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7685 - val_loss: 0.5232 - val_accuracy: 0.7825\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7685 - val_loss: 0.5233 - val_accuracy: 0.7825\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7685 - val_loss: 0.5239 - val_accuracy: 0.7825\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7685 - val_loss: 0.5260 - val_accuracy: 0.7825\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7685 - val_loss: 0.5322 - val_accuracy: 0.7825\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5427 - accuracy: 0.7685 - val_loss: 0.5317 - val_accuracy: 0.7825\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7685 - val_loss: 0.5241 - val_accuracy: 0.7825\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7685 - val_loss: 0.5232 - val_accuracy: 0.7825\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5426 - accuracy: 0.7685 - val_loss: 0.5246 - val_accuracy: 0.7825\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7685 - val_loss: 0.5251 - val_accuracy: 0.7825\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7685 - val_loss: 0.5332 - val_accuracy: 0.7825\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7685 - val_loss: 0.5232 - val_accuracy: 0.7825\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7685 - val_loss: 0.5235 - val_accuracy: 0.7825\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7685 - val_loss: 0.5376 - val_accuracy: 0.7825\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5427 - accuracy: 0.7685 - val_loss: 0.5231 - val_accuracy: 0.7825\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7685 - val_loss: 0.5229 - val_accuracy: 0.7825\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7685 - val_loss: 0.5253 - val_accuracy: 0.7825\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7685 - val_loss: 0.5232 - val_accuracy: 0.7825\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7685 - val_loss: 0.5236 - val_accuracy: 0.7825\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7685 - val_loss: 0.5229 - val_accuracy: 0.7825\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7685 - val_loss: 0.5230 - val_accuracy: 0.7825\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7685 - val_loss: 0.5230 - val_accuracy: 0.7825\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7685 - val_loss: 0.5239 - val_accuracy: 0.7825\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7685 - val_loss: 0.5248 - val_accuracy: 0.7825\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7685 - val_loss: 0.5261 - val_accuracy: 0.7825\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7685 - val_loss: 0.5247 - val_accuracy: 0.7825\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7685 - val_loss: 0.5232 - val_accuracy: 0.7825\n",
      "Epoch 39/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7685 - val_loss: 0.5246 - val_accuracy: 0.7825\n",
      "Epoch 40/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7685 - val_loss: 0.5246 - val_accuracy: 0.7825\n",
      "Epoch 41/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7685 - val_loss: 0.5229 - val_accuracy: 0.7825\n",
      "Epoch 42/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7685 - val_loss: 0.5263 - val_accuracy: 0.7825\n",
      "Epoch 43/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7685 - val_loss: 0.5316 - val_accuracy: 0.7825\n",
      "Epoch 44/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7685 - val_loss: 0.5227 - val_accuracy: 0.7825\n",
      "Epoch 45/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7685 - val_loss: 0.5250 - val_accuracy: 0.7825\n",
      "Epoch 46/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7685 - val_loss: 0.5233 - val_accuracy: 0.7825\n",
      "Epoch 47/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7685 - val_loss: 0.5228 - val_accuracy: 0.7825\n",
      "Epoch 48/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7685 - val_loss: 0.5290 - val_accuracy: 0.7825\n",
      "Epoch 49/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7685 - val_loss: 0.5226 - val_accuracy: 0.7825\n",
      "Epoch 50/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7685 - val_loss: 0.5232 - val_accuracy: 0.7825\n",
      "Epoch 51/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7685 - val_loss: 0.5321 - val_accuracy: 0.7825\n",
      "Epoch 52/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7685 - val_loss: 0.5230 - val_accuracy: 0.7825\n",
      "Epoch 53/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5415 - accuracy: 0.7685 - val_loss: 0.5225 - val_accuracy: 0.7825\n",
      "Epoch 54/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7685 - val_loss: 0.5229 - val_accuracy: 0.7825\n",
      "Epoch 55/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7685 - val_loss: 0.5259 - val_accuracy: 0.7825\n",
      "Epoch 56/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7685 - val_loss: 0.5230 - val_accuracy: 0.7825\n",
      "Epoch 57/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7685 - val_loss: 0.5234 - val_accuracy: 0.7825\n",
      "Epoch 58/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7685 - val_loss: 0.5256 - val_accuracy: 0.7825\n",
      "Epoch 59/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7685 - val_loss: 0.5229 - val_accuracy: 0.7825\n",
      "Epoch 60/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7685 - val_loss: 0.5224 - val_accuracy: 0.7825\n",
      "Epoch 61/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7685 - val_loss: 0.5243 - val_accuracy: 0.7825\n",
      "Epoch 62/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7685 - val_loss: 0.5228 - val_accuracy: 0.7825\n",
      "Epoch 63/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7685 - val_loss: 0.5252 - val_accuracy: 0.7825\n",
      "Epoch 64/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7685 - val_loss: 0.5234 - val_accuracy: 0.7825\n",
      "Epoch 65/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7685 - val_loss: 0.5226 - val_accuracy: 0.7825\n",
      "Epoch 66/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7685 - val_loss: 0.5239 - val_accuracy: 0.7825\n",
      "Epoch 67/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7685 - val_loss: 0.5241 - val_accuracy: 0.7825\n",
      "Epoch 68/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7685 - val_loss: 0.5228 - val_accuracy: 0.7825\n",
      "Epoch 69/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5415 - accuracy: 0.7685 - val_loss: 0.5237 - val_accuracy: 0.7825\n",
      "Epoch 70/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7685 - val_loss: 0.5261 - val_accuracy: 0.7825\n",
      "Epoch 71/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7685 - val_loss: 0.5247 - val_accuracy: 0.7825\n",
      "Epoch 72/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7685 - val_loss: 0.5220 - val_accuracy: 0.7825\n",
      "Epoch 73/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7685 - val_loss: 0.5224 - val_accuracy: 0.7825\n",
      "Epoch 74/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5407 - accuracy: 0.7685 - val_loss: 0.5220 - val_accuracy: 0.7825\n",
      "Epoch 75/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7685 - val_loss: 0.5239 - val_accuracy: 0.7825\n",
      "Epoch 76/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7685 - val_loss: 0.5268 - val_accuracy: 0.7825\n",
      "Epoch 77/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7685 - val_loss: 0.5225 - val_accuracy: 0.7825\n",
      "Epoch 78/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7685 - val_loss: 0.5280 - val_accuracy: 0.7825\n",
      "Epoch 79/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7685 - val_loss: 0.5264 - val_accuracy: 0.7825\n",
      "Epoch 80/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7685 - val_loss: 0.5221 - val_accuracy: 0.7825\n",
      "Epoch 81/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7685 - val_loss: 0.5219 - val_accuracy: 0.7825\n",
      "Epoch 82/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7685 - val_loss: 0.5251 - val_accuracy: 0.7825\n",
      "Epoch 83/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5407 - accuracy: 0.7685 - val_loss: 0.5249 - val_accuracy: 0.7825\n",
      "Epoch 84/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7685 - val_loss: 0.5239 - val_accuracy: 0.7825\n",
      "Epoch 85/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5405 - accuracy: 0.7685 - val_loss: 0.5217 - val_accuracy: 0.7825\n",
      "Epoch 86/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7685 - val_loss: 0.5244 - val_accuracy: 0.7825\n",
      "Epoch 87/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5404 - accuracy: 0.7685 - val_loss: 0.5216 - val_accuracy: 0.7825\n",
      "Epoch 88/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7685 - val_loss: 0.5226 - val_accuracy: 0.7825\n",
      "Epoch 89/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5408 - accuracy: 0.7685 - val_loss: 0.5221 - val_accuracy: 0.7825\n",
      "Epoch 90/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7685 - val_loss: 0.5242 - val_accuracy: 0.7825\n",
      "Epoch 91/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5405 - accuracy: 0.7685 - val_loss: 0.5321 - val_accuracy: 0.7825\n",
      "Epoch 92/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7685 - val_loss: 0.5220 - val_accuracy: 0.7825\n",
      "Epoch 93/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5408 - accuracy: 0.7685 - val_loss: 0.5300 - val_accuracy: 0.7825\n",
      "Epoch 94/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7685 - val_loss: 0.5231 - val_accuracy: 0.7825\n",
      "Epoch 95/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5403 - accuracy: 0.7685 - val_loss: 0.5215 - val_accuracy: 0.7825\n",
      "Epoch 96/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5406 - accuracy: 0.7685 - val_loss: 0.5224 - val_accuracy: 0.7825\n",
      "Epoch 97/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5407 - accuracy: 0.7685 - val_loss: 0.5217 - val_accuracy: 0.7825\n",
      "Epoch 98/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.5404 - accuracy: 0.7685 - val_loss: 0.5213 - val_accuracy: 0.7825\n",
      "Epoch 99/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5405 - accuracy: 0.7685 - val_loss: 0.5212 - val_accuracy: 0.7825\n",
      "Epoch 100/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.5404 - accuracy: 0.7685 - val_loss: 0.5210 - val_accuracy: 0.7825\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7623\n",
      "[CV] END activation_function=sigmoid, n_hidden=5, n_neurons=35; total time=  53.1s\n",
      "Epoch 1/100\n",
      "338/338 [==============================] - 1s 3ms/step - loss: 3.5706 - accuracy: 0.6901 - val_loss: 6.2197 - val_accuracy: 0.5883\n",
      "Epoch 2/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 4.9941 - accuracy: 0.6620 - val_loss: 2.8113 - val_accuracy: 0.8125\n",
      "Epoch 3/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 3.5652 - accuracy: 0.7590 - val_loss: 2.8287 - val_accuracy: 0.8100\n",
      "Epoch 4/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 2.8118 - accuracy: 0.8100 - val_loss: 3.2693 - val_accuracy: 0.7833\n",
      "Epoch 5/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 2.8146 - accuracy: 0.8132 - val_loss: 2.8577 - val_accuracy: 0.8092\n",
      "Epoch 6/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 2.8949 - accuracy: 0.8060 - val_loss: 2.7557 - val_accuracy: 0.8158\n",
      "Epoch 7/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 3.0467 - accuracy: 0.7967 - val_loss: 3.9809 - val_accuracy: 0.7358\n",
      "Epoch 8/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 3.4740 - accuracy: 0.7698 - val_loss: 3.2475 - val_accuracy: 0.7833\n",
      "Epoch 9/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 3.0531 - accuracy: 0.7980 - val_loss: 3.0162 - val_accuracy: 0.8017\n",
      "Epoch 10/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 2.7665 - accuracy: 0.8160 - val_loss: 2.7482 - val_accuracy: 0.8175\n",
      "Epoch 11/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 3.7069 - accuracy: 0.7559 - val_loss: 5.6960 - val_accuracy: 0.6242\n",
      "Epoch 12/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 3.9734 - accuracy: 0.7389 - val_loss: 3.5206 - val_accuracy: 0.7708\n",
      "Epoch 13/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 3.3212 - accuracy: 0.7830 - val_loss: 3.4092 - val_accuracy: 0.7750\n",
      "Epoch 14/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 3.3053 - accuracy: 0.7842 - val_loss: 3.3809 - val_accuracy: 0.7783\n",
      "Epoch 15/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 3.3019 - accuracy: 0.7844 - val_loss: 3.4445 - val_accuracy: 0.7742\n",
      "Epoch 16/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 3.2938 - accuracy: 0.7853 - val_loss: 3.4607 - val_accuracy: 0.7725\n",
      "Epoch 17/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 4.7732 - accuracy: 0.6873 - val_loss: 5.5739 - val_accuracy: 0.6350\n",
      "Epoch 18/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 5.5208 - accuracy: 0.6383 - val_loss: 5.5612 - val_accuracy: 0.6358\n",
      "Epoch 19/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 5.5068 - accuracy: 0.6392 - val_loss: 5.5358 - val_accuracy: 0.6375\n",
      "Epoch 20/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 5.4483 - accuracy: 0.6430 - val_loss: 5.3960 - val_accuracy: 0.6467\n",
      "Epoch 21/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 5.4207 - accuracy: 0.6449 - val_loss: 5.3960 - val_accuracy: 0.6467\n",
      "Epoch 22/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 5.4097 - accuracy: 0.6455 - val_loss: 5.3586 - val_accuracy: 0.6483\n",
      "Epoch 23/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 5.3631 - accuracy: 0.6486 - val_loss: 5.3072 - val_accuracy: 0.6525\n",
      "Epoch 24/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 5.3628 - accuracy: 0.6488 - val_loss: 5.3072 - val_accuracy: 0.6525\n",
      "Epoch 25/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 5.3628 - accuracy: 0.6488 - val_loss: 5.3072 - val_accuracy: 0.6525\n",
      "Epoch 26/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 5.3628 - accuracy: 0.6488 - val_loss: 5.3072 - val_accuracy: 0.6525\n",
      "Epoch 27/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 5.3628 - accuracy: 0.6488 - val_loss: 5.3072 - val_accuracy: 0.6525\n",
      "Epoch 28/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 5.3628 - accuracy: 0.6488 - val_loss: 5.3072 - val_accuracy: 0.6525\n",
      "Epoch 29/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 5.3628 - accuracy: 0.6488 - val_loss: 5.3072 - val_accuracy: 0.6525\n",
      "Epoch 30/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 5.3628 - accuracy: 0.6488 - val_loss: 5.3072 - val_accuracy: 0.6525\n",
      "Epoch 30: early stopping\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f980d9df210>,\n",
       "                   param_distributions={'activation_function': ['relu', 'elu',\n",
       "                                                                'sigmoid'],\n",
       "                                        'n_hidden': [2, 3, 4, 5],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
       "                   verbose=2)"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "rnd_search_cv.best_params_"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "erh87v6Ctmy4",
    "outputId": "ee63d869-cd4f-4c99-90f3-ecd1baff96f3"
   },
   "execution_count": 88,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'activation_function': 'elu', 'n_hidden': 2, 'n_neurons': 71}"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    ""
   ],
   "metadata": {
    "id": "3TcqkJAYuLMj"
   },
   "execution_count": 88,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2.6. Porównanie modeli głębokich"
   ],
   "metadata": {
    "id": "fr8vPolRs32Z"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(pd.DataFrame(history1.history['val_accuracy']), label='Sieć bez bajerów')\n",
    "plt.plot(pd.DataFrame(history2.history['val_accuracy']), label='Sieć z earlystoppingiem')\n",
    "plt.plot(pd.DataFrame(history3.history['val_accuracy']), label='Sieć z BatchNormalization')\n",
    "plt.plot(pd.DataFrame(history4.history['val_accuracy']), label='Sieć z BatchNormalizastion i Dropoutem')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.rcParams[\"figure.figsize\"] = (25,12)\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 651
    },
    "id": "9stnNx5EtAmA",
    "outputId": "af8aa288-64cf-426a-b094-a2b94dcf0ce8"
   },
   "execution_count": 105,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 1800x864 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "colab": {
   "name": "projekt_australia.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}